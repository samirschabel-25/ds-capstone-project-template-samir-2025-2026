{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e729b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 17:51:47.889767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema OK (pokemon_card_samples_fb). Counts: {'EX': 34, 'GD': 30, 'LP': 30, 'NM': 31, 'PL': 28, 'PO': 25, 'TOTAL': 178}\n",
      "‚úÖ Loaded back model: card_back_condition_model.keras\n",
      "‚úÖ Loaded front model: card_front_condition_model.keras\n",
      "‚ÑπÔ∏è Ref cache ist leer beim Start (Fast-Startup). Klicke 'üîÑ Cache neu laden', wenn du ihn brauchst.\n",
      "üëâ √ñffne am Handy (gleiches WLAN): http://192.168.8.17:52157\n",
      "* Running on local URL:  http://0.0.0.0:52157\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:52157/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# NOTEBOOK 2 (FRONT+BACK Pflicht) ‚Äî FULL CODE (ROBUST + PDF PLOTS ONLY)\n",
    "# ‚úÖ Zwei Modelle (Front/Back) + kNN pro Seite\n",
    "# ‚úÖ Combined kNN Cache (Front+Back Embedding) als Tie-Breaker bei Disagreement\n",
    "# ‚úÖ FINAL = Combined, aber: wenn Back != Front ‚Üí kNN/Guardrails entscheiden\n",
    "# ‚úÖ Grades: Back, Front, Combined (je 1‚Äì10)\n",
    "# ‚úÖ PDF Report: 1 Seite (Badge + PLOTS ONLY) ‚Äî keine Tabellen, keine Sources\n",
    "# =========================================================\n",
    "\n",
    "# =========================\n",
    "# Zelle: Install\n",
    "# =========================\n",
    "# %pip install --quiet tensorflow opencv-python-headless pillow gradio psycopg2-binary python-dotenv numpy matplotlib reportlab\n",
    "\n",
    "%pip install --quiet tensorflow\n",
    "\n",
    "# =========================\n",
    "# Imports & Settings\n",
    "# =========================\n",
    "import os, io, json, uuid, hashlib, socket, traceback, datetime\n",
    "from collections import Counter\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import gradio as gr\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.utils import ImageReader\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.units import mm\n",
    "from reportlab.pdfbase.pdfmetrics import stringWidth\n",
    "\n",
    "\n",
    "# ====== DB Table ======\n",
    "TABLE = \"pokemon_card_samples_fb\"\n",
    "\n",
    "# ====== Labels ======\n",
    "LABELS = [\"NM\", \"EX\", \"GD\", \"LP\", \"PL\", \"PO\"]\n",
    "LABEL2IDX = {l:i for i,l in enumerate(LABELS)}\n",
    "IDX2LABEL = {i:l for l,i in LABEL2IDX.items()}\n",
    "LABEL_IDX = LABEL2IDX\n",
    "\n",
    "IMG_H = 352\n",
    "IMG_W = 256\n",
    "\n",
    "# ====== Multi-View ======\n",
    "CROP_FRAC = 0.62\n",
    "AUG_FULL = True\n",
    "AUG_CORNERS = True\n",
    "\n",
    "# Inferenz-stabiler: Jitter runter, Inference-AUG aus\n",
    "USE_JITTER = True\n",
    "N_JITTER = 2\n",
    "JITTER_MAX_PX = 4\n",
    "\n",
    "# ====== Embedding / kNN ======\n",
    "TOPK = 10\n",
    "EMB_DIM = 128\n",
    "KNN_K = 10   # ‚úÖ statt 7: wir nutzen wirklich die 10 n√§chsten\n",
    "\n",
    "# ====== Embedding: nur Rand/Ecken (gegen Artwork-√Ñhnlichkeit) ======\n",
    "EMB_RING_FRAC_BACK  = 0.18   # Anteil je Seite, der als \"Rand\" bleibt\n",
    "EMB_RING_FRAC_FRONT = 0.20   # Front etwas dicker, weil Artwork/Holo stark st√∂rt\n",
    "EMB_FILL_VALUE = 128         # Grau f√ºllen (neutral)\n",
    "\n",
    "\n",
    "# Per-Side Fusion (nur wenn CNN unsicher)\n",
    "USE_KNN_FUSION = True\n",
    "FUSION_CONF_TH = 0.50\n",
    "\n",
    "# kNN Mischung in Side-Probs (f√ºr Combined-Reporting)\n",
    "KNN_MIX_BASE = 0.12\n",
    "\n",
    "# kNN Override nur bei wirklich guter √Ñhnlichkeit\n",
    "KNN_FUSION_MIN_BEST_SIM = 0.78\n",
    "KNN_FUSION_MIN_CONF = 0.45\n",
    "KNN_MIX_MIN_BEST_SIM = 0.72\n",
    "\n",
    "# ====== Ensemble ======\n",
    "ENSEMBLE_RUNS = 10\n",
    "DETERMINISTIC_PER_IMAGE = True\n",
    "SEED_STEP = 10007\n",
    "\n",
    "# ====== Training ======\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_HEAD = 6\n",
    "EPOCHS_FINETUNE = 6\n",
    "LR_HEAD = 1e-3\n",
    "LR_FINETUNE = 2e-4\n",
    "\n",
    "MODEL_PATH_BACK  = \"card_back_condition_model.keras\"\n",
    "MODEL_PATH_FRONT = \"card_front_condition_model.keras\"\n",
    "\n",
    "REPORT_DIR = \"reports\"\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "# ====== Preprocess ======\n",
    "QUAD_EXPAND_BACK  = 1.04\n",
    "QUAD_EXPAND_FRONT = 1.03\n",
    "CORNER_RADIUS_PX = int(round(IMG_W * 0.05))\n",
    "APPLY_ROUNDED_MASK_TO_IMAGE = False\n",
    "\n",
    "# ====== Combined Decision ======\n",
    "WEIGHT_BACK  = 0.50\n",
    "WEIGHT_FRONT = 0.50\n",
    "\n",
    "# ====== Local Retrieval (Top-10 Combined Neighbors) ======\n",
    "USE_LOCAL_TOP10 = True\n",
    "\n",
    "LOCAL_TOPK = 10                 # genau 10 Nachbarn\n",
    "LOCAL_PRIOR_POWER = 3.0         # sim^power -> betont sehr √§hnliche st√§rker\n",
    "LOCAL_MIN_SIM_FOR_MIX = 0.75    # ab welcher best_sim wir √ºberhaupt mischen\n",
    "LOCAL_MAX_MIX = 0.35            # max Anteil Neighbor-Verteilung im Final\n",
    "\n",
    "\n",
    "# ‚úÖ Wenn Back != Front ‚Üí Combined-Tiebreak durch kNN/Guardrails\n",
    "COMBINED_TIEBREAK_BY_KNN = True\n",
    "\n",
    "# Inference Augmentierung (bei Ausrei√üern: AUS)\n",
    "INFER_AUG = False\n",
    "\n",
    "\n",
    "# ====== Robustness / Guardrails ======\n",
    "VIEW_TRIM_Q = 0.20                # 20% der schlimmsten/besten Views wegtrimmen\n",
    "MAX_OUTLIER_JUMP = 2              # mehr als 2 Klassen Sprung -> nur bei starker Evidenz erlauben\n",
    "\n",
    "EXTREME_ALLOW_CNN_CONF = 0.86     # wenn CNN sehr sicher ist, darf auch extrem sein\n",
    "EXTREME_ALLOW_SIM = 0.90          # oder wenn kNN sehr √§hnlich ist...\n",
    "EXTREME_ALLOW_KNN_CONF = 0.60     # ...und kNN konsistent ist\n",
    "\n",
    "DISAGREE_HARD_DIFF = 3            # NM vs PL/PO etc. => \"harte\" Diskrepanz\n",
    "DISAGREE_REQUIRE_SIM = 0.86       # combined-kNN wird nur genutzt, wenn best_sim hoch\n",
    "DISAGREE_REQUIRE_CONF = 0.55      # und combined-kNN conf ausreichend ist\n",
    "\n",
    "REQUIRE_EXTRACTION = True         # wenn Warp/Quad nicht sauber ‚Üí lieber abbrechen statt Mist klassifizieren\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DB Verbindung + Schema\n",
    "# =========================\n",
    "def get_conn():\n",
    "    return psycopg2.connect(\n",
    "        host=os.getenv(\"PGHOST\", \"127.0.0.1\"),\n",
    "        port=int(os.getenv(\"PGPORT\", \"5433\")),\n",
    "        dbname=os.getenv(\"PGDATABASE\", \"sam1988\"),\n",
    "        user=os.getenv(\"PGUSER\", \"postgres\"),\n",
    "        password=os.getenv(\"PGPASSWORD\", \"\")\n",
    "    )\n",
    "\n",
    "def ensure_schema():\n",
    "    labels_sql = \",\".join([f\"'{l}'\" for l in LABELS])\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {TABLE} (\n",
    "                id UUID PRIMARY KEY,\n",
    "                created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n",
    "\n",
    "                label TEXT NOT NULL CHECK (label IN ({labels_sql})),\n",
    "                note TEXT,\n",
    "\n",
    "                -- BACK (Pflicht)\n",
    "                back_raw_sha256 TEXT NOT NULL UNIQUE,\n",
    "                back_raw_format TEXT NOT NULL,\n",
    "                back_raw_w INT,\n",
    "                back_raw_h INT,\n",
    "                back_raw_bytes BYTEA NOT NULL,\n",
    "\n",
    "                back_proc_format TEXT NOT NULL,\n",
    "                back_proc_w INT NOT NULL,\n",
    "                back_proc_h INT NOT NULL,\n",
    "                back_proc_bytes BYTEA NOT NULL,\n",
    "\n",
    "                back_proc_mask_format TEXT NOT NULL DEFAULT 'png',\n",
    "                back_proc_mask_w INT NOT NULL DEFAULT {IMG_W},\n",
    "                back_proc_mask_h INT NOT NULL DEFAULT {IMG_H},\n",
    "                back_proc_mask_bytes BYTEA,\n",
    "\n",
    "                back_proc_method TEXT,\n",
    "                back_proc_quad_expand REAL,\n",
    "\n",
    "                -- FRONT (Pflicht)\n",
    "                front_raw_sha256 TEXT NOT NULL UNIQUE,\n",
    "                front_raw_format TEXT NOT NULL,\n",
    "                front_raw_w INT,\n",
    "                front_raw_h INT,\n",
    "                front_raw_bytes BYTEA NOT NULL,\n",
    "\n",
    "                front_proc_format TEXT NOT NULL,\n",
    "                front_proc_w INT NOT NULL,\n",
    "                front_proc_h INT NOT NULL,\n",
    "                front_proc_bytes BYTEA NOT NULL,\n",
    "\n",
    "                front_proc_mask_format TEXT NOT NULL DEFAULT 'png',\n",
    "                front_proc_mask_w INT NOT NULL DEFAULT {IMG_W},\n",
    "                front_proc_mask_h INT NOT NULL DEFAULT {IMG_H},\n",
    "                front_proc_mask_bytes BYTEA,\n",
    "\n",
    "                front_proc_method TEXT,\n",
    "                front_proc_quad_expand REAL\n",
    "            );\n",
    "            \"\"\")\n",
    "            cur.execute(f\"CREATE INDEX IF NOT EXISTS idx_{TABLE}_label ON {TABLE}(label);\")\n",
    "            cur.execute(f\"CREATE INDEX IF NOT EXISTS idx_{TABLE}_created_at ON {TABLE}(created_at DESC);\")\n",
    "\n",
    "def db_counts():\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT label, COUNT(*)::int AS n\n",
    "                FROM {TABLE}\n",
    "                GROUP BY label\n",
    "                ORDER BY label;\n",
    "            \"\"\")\n",
    "            rows = cur.fetchall()\n",
    "    counts = {r[\"label\"]: r[\"n\"] for r in rows}\n",
    "    for l in LABELS:\n",
    "        counts.setdefault(l, 0)\n",
    "    counts[\"TOTAL\"] = sum(counts[l] for l in LABELS)\n",
    "    return counts\n",
    "\n",
    "def fmt_pg_error(e: Exception) -> str:\n",
    "    if isinstance(e, psycopg2.Error):\n",
    "        parts = [f\"{type(e).__name__}: {e}\"]\n",
    "        if getattr(e, \"pgcode\", None): parts.append(f\"pgcode: {e.pgcode}\")\n",
    "        if getattr(e, \"pgerror\", None): parts.append(f\"pgerror: {e.pgerror}\")\n",
    "        diag = getattr(e, \"diag\", None)\n",
    "        if diag is not None:\n",
    "            for k in [\"message_detail\",\"message_hint\",\"schema_name\",\"table_name\",\"column_name\",\"constraint_name\"]:\n",
    "                v = getattr(diag, k, None)\n",
    "                if v: parts.append(f\"{k}: {v}\")\n",
    "        return \"\\n\".join(parts)\n",
    "    return f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "ensure_schema()\n",
    "print(f\"‚úÖ Schema OK ({TABLE}). Counts:\", db_counts())\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils (Images / Views) + PREPROCESS (Warp)\n",
    "# =========================\n",
    "def proc_png_bytes_to_np(proc_bytes: bytes) -> np.ndarray:\n",
    "    pil = Image.open(io.BytesIO(proc_bytes)).convert(\"RGB\")\n",
    "    arr = np.array(pil, dtype=np.uint8)\n",
    "    if arr.shape[:2] != (IMG_H, IMG_W):\n",
    "        arr = cv2.resize(arr, (IMG_W, IMG_H), interpolation=cv2.INTER_AREA)\n",
    "    return arr\n",
    "\n",
    "def resize_to_base(img: np.ndarray) -> np.ndarray:\n",
    "    if img.shape[:2] != (IMG_H, IMG_W):\n",
    "        img = cv2.resize(img, (IMG_W, IMG_H), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def mask_center_keep_border(img_uint8: np.ndarray, ring_frac: float, fill: int = 128) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Neutralisiert die Bildmitte, l√§sst nur einen Rand-Ring stehen.\n",
    "    Dadurch wird kNN/Embedding condition-orientiert (Whitening/Kanten),\n",
    "    statt artwork-orientiert.\n",
    "    \"\"\"\n",
    "    img = img_uint8.copy()\n",
    "    H, W = img.shape[:2]\n",
    "    t = int(round(min(H, W) * float(ring_frac)))\n",
    "    y0, y1 = t, H - t\n",
    "    x0, x1 = t, W - t\n",
    "    if y1 > y0 and x1 > x0:\n",
    "        img[y0:y1, x0:x1] = int(fill)\n",
    "    return img\n",
    "\n",
    "\n",
    "def seed_from_image_uint8(arr_uint8: np.ndarray) -> int:\n",
    "    h = hashlib.sha256(arr_uint8.tobytes()).digest()\n",
    "    return int.from_bytes(h[:8], \"little\", signed=False)\n",
    "\n",
    "def jitter_perspective(img: np.ndarray, max_px: int = 6, rng: Optional[np.random.Generator] = None) -> np.ndarray:\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    H, W = img.shape[:2]\n",
    "    src = np.array([[0,0],[W-1,0],[W-1,H-1],[0,H-1]], dtype=np.float32)\n",
    "    j = rng.integers(-max_px, max_px+1, size=(4,2)).astype(np.float32)\n",
    "    dst = np.clip(src + j, [0,0], [W-1,H-1]).astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    out = cv2.warpPerspective(img, M, (W, H), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
    "    return out\n",
    "\n",
    "def make_views(img_uint8: np.ndarray, rng: Optional[np.random.Generator] = None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    img = resize_to_base(img_uint8)\n",
    "    H, W = img.shape[:2]\n",
    "    ch = int(round(H * CROP_FRAC))\n",
    "    cw = int(round(W * CROP_FRAC))\n",
    "\n",
    "    def crop(y0, x0, y1, x1):\n",
    "        c = img[y0:y1, x0:x1]\n",
    "        return resize_to_base(c)\n",
    "\n",
    "    full = img\n",
    "    tl = crop(0, 0, ch, cw)\n",
    "    tr = crop(0, W-cw, ch, W)\n",
    "    bl = crop(H-ch, 0, H, cw)\n",
    "    br = crop(H-ch, W-cw, H, W)\n",
    "\n",
    "    y_mid0 = (H - ch)//2\n",
    "    x_mid0 = (W - cw)//2\n",
    "    top = crop(0, x_mid0, ch, x_mid0+cw)\n",
    "    bottom = crop(H-ch, x_mid0, H, x_mid0+cw)\n",
    "    left = crop(y_mid0, 0, y_mid0+ch, cw)\n",
    "    right = crop(y_mid0, W-cw, y_mid0+ch, W)\n",
    "\n",
    "    base = [\n",
    "        (\"full\", full),\n",
    "        (\"corner_tl\", tl), (\"corner_tr\", tr), (\"corner_bl\", bl), (\"corner_br\", br),\n",
    "        (\"edge_top\", top), (\"edge_bottom\", bottom), (\"edge_left\", left), (\"edge_right\", right),\n",
    "    ]\n",
    "\n",
    "    def aug(name, v):\n",
    "        return [\n",
    "            (name, v),\n",
    "            (name + \"_hflip\", cv2.flip(v, 1)),\n",
    "            (name + \"_vflip\", cv2.flip(v, 0)),\n",
    "            (name + \"_rot180\", cv2.rotate(v, cv2.ROTATE_180)),\n",
    "        ]\n",
    "\n",
    "    views = []\n",
    "    views.extend(base)\n",
    "    if AUG_FULL:\n",
    "        views.extend(aug(\"full\", full)[1:])\n",
    "    if AUG_CORNERS:\n",
    "        for nm, v in [(\"corner_tl\", tl), (\"corner_tr\", tr), (\"corner_bl\", bl), (\"corner_br\", br)]:\n",
    "            views.extend(aug(nm, v)[1:])\n",
    "    if USE_JITTER:\n",
    "        for j in range(N_JITTER):\n",
    "            views.append((f\"full_jitter{j+1}\", jitter_perspective(full, max_px=JITTER_MAX_PX, rng=rng)))\n",
    "\n",
    "    imgs  = [im for _,im in views]\n",
    "    names = [n for n,_ in views]\n",
    "    return imgs, names\n",
    "\n",
    "def infer_augment_np(x_uint8: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    if not INFER_AUG:\n",
    "        return x_uint8.astype(np.float32)\n",
    "    y = x_uint8.astype(np.float32)\n",
    "    y += float(rng.uniform(-8, 8))  # brightness\n",
    "    c = float(rng.uniform(0.95, 1.05))  # contrast\n",
    "    y = (y - 128.0) * c + 128.0\n",
    "    y += rng.normal(0, 2.0, size=y.shape).astype(np.float32)  # noise\n",
    "    return np.clip(y, 0, 255).astype(np.float32)\n",
    "\n",
    "# ---- Warp/Normalize ----\n",
    "def pil_to_jpeg_bytes(pil_img: Image.Image, quality: int = 92) -> bytes:\n",
    "    pil_img = ImageOps.exif_transpose(pil_img).convert(\"RGB\")\n",
    "    buf = io.BytesIO()\n",
    "    pil_img.save(buf, format=\"JPEG\", quality=quality, optimize=True)\n",
    "    return buf.getvalue()\n",
    "\n",
    "def bgr_from_pil(pil_img: Image.Image) -> np.ndarray:\n",
    "    rgb = np.array(ImageOps.exif_transpose(pil_img).convert(\"RGB\"))\n",
    "    return cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def order_points(pts):\n",
    "    pts = np.array(pts, dtype=np.float32)\n",
    "    rect = np.zeros((4, 2), dtype=np.float32)\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]      # tl\n",
    "    rect[2] = pts[np.argmax(s)]      # br\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]   # tr\n",
    "    rect[3] = pts[np.argmax(diff)]   # bl\n",
    "    return rect\n",
    "\n",
    "# ---- Quad validation (verhindert falsche Warps auf Hintergrund) ----\n",
    "AR_MIN, AR_MAX = 0.55, 0.90             # Pokemon-Karte ~0.72 (min/max erlaubt etwas Spielraum)\n",
    "MIN_AREA_RATIO_BACK  = 0.12\n",
    "MIN_AREA_RATIO_FRONT = 0.18\n",
    "\n",
    "def quad_is_reasonable(bgr: np.ndarray, quad: np.ndarray, min_area_ratio: float) -> bool:\n",
    "    q = order_points(np.asarray(quad, dtype=np.float32))\n",
    "    H, W = bgr.shape[:2]\n",
    "    area = abs(cv2.contourArea(q))\n",
    "    if area < (min_area_ratio * H * W):\n",
    "        return False\n",
    "\n",
    "    rect = cv2.minAreaRect(q)\n",
    "    rw, rh = rect[1]\n",
    "    if rw <= 1 or rh <= 1:\n",
    "        return False\n",
    "\n",
    "    ar = min(rw, rh) / max(rw, rh)  # 0..1\n",
    "    if not (AR_MIN <= ar <= AR_MAX):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def expand_quad(quad: np.ndarray, scale: float) -> np.ndarray:\n",
    "    q = quad.astype(np.float32)\n",
    "    c = q.mean(axis=0, keepdims=True)\n",
    "    return (c + (q - c) * scale).astype(np.float32)\n",
    "\n",
    "def warp_quad(bgr, quad, out_w=IMG_W, out_h=IMG_H):\n",
    "    rect = order_points(quad)\n",
    "    dst = np.array([[0,0],[out_w-1,0],[out_w-1,out_h-1],[0,out_h-1]], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(\n",
    "        bgr, M, (out_w, out_h),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_REFLECT\n",
    "    )\n",
    "\n",
    "def overlay_quad_debug(bgr, quad):\n",
    "    dbg = bgr.copy()\n",
    "    q = order_points(quad).astype(int)\n",
    "    cv2.polylines(dbg, [q], isClosed=True, color=(0, 255, 0), thickness=4)\n",
    "    for (x, y) in q:\n",
    "        cv2.circle(dbg, (x, y), 10, (0, 0, 255), -1)\n",
    "    return dbg\n",
    "\n",
    "def try_extract_by_blue_mask(bgr):\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([80, 40, 40], dtype=np.uint8)\n",
    "    upper = np.array([150, 255, 255], dtype=np.uint8)\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  k, iterations=1)\n",
    "\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area < 0.10 * (bgr.shape[0] * bgr.shape[1]):\n",
    "        return None\n",
    "\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        return approx.reshape(-1, 2)\n",
    "\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    return cv2.boxPoints(rect)\n",
    "\n",
    "def try_extract_by_edges(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edges = cv2.dilate(edges, None, iterations=2)\n",
    "\n",
    "    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:10]\n",
    "    for cnt in cnts:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < 0.10 * (bgr.shape[0] * bgr.shape[1]):\n",
    "            continue\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            return approx.reshape(-1, 2)\n",
    "    return None\n",
    "\n",
    "def try_extract_by_adaptive_thresh(bgr):\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    th = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,\n",
    "        31, 7\n",
    "    )\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, k, iterations=2)\n",
    "\n",
    "    cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not cnts:\n",
    "        return None\n",
    "\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if area < 0.10 * (bgr.shape[0] * bgr.shape[1]):\n",
    "        return None\n",
    "\n",
    "    peri = cv2.arcLength(cnt, True)\n",
    "    approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        return approx.reshape(-1, 2)\n",
    "\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    return cv2.boxPoints(rect)\n",
    "\n",
    "def normalize_to_target(bgr, side: str, out_w=IMG_W, out_h=IMG_H):\n",
    "    if side == \"back\":\n",
    "        candidates = [(\"blue_mask\", try_extract_by_blue_mask), (\"edges\", try_extract_by_edges), (\"adaptive\", try_extract_by_adaptive_thresh)]\n",
    "        quad_expand = QUAD_EXPAND_BACK\n",
    "        min_area_ratio = MIN_AREA_RATIO_BACK\n",
    "    else:\n",
    "        candidates = [(\"edges\", try_extract_by_edges), (\"adaptive\", try_extract_by_adaptive_thresh), (\"blue_mask\", try_extract_by_blue_mask)]\n",
    "        quad_expand = QUAD_EXPAND_FRONT\n",
    "        min_area_ratio = MIN_AREA_RATIO_FRONT\n",
    "\n",
    "    quad = None\n",
    "    method = None\n",
    "    for nm, fn in candidates:\n",
    "        q = fn(bgr)\n",
    "        if q is None:\n",
    "            continue\n",
    "        if not quad_is_reasonable(bgr, q, min_area_ratio=min_area_ratio):\n",
    "            continue\n",
    "        quad = q\n",
    "        method = nm\n",
    "        break\n",
    "\n",
    "    if quad is None:\n",
    "        resized = cv2.resize(bgr, (out_w, out_h), interpolation=cv2.INTER_AREA)\n",
    "        return resized, \"fallback_resize\", False, None, quad_expand\n",
    "\n",
    "    quad = expand_quad(np.array(quad), scale=quad_expand)\n",
    "    dbg = overlay_quad_debug(bgr, quad)\n",
    "    warped = warp_quad(bgr, quad, out_w=out_w, out_h=out_h)\n",
    "\n",
    "    if warped.shape[1] > warped.shape[0]:\n",
    "        warped = cv2.rotate(warped, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    warped = cv2.resize(warped, (out_w, out_h), interpolation=cv2.INTER_AREA)\n",
    "    return warped, f\"{method}_expand{quad_expand}\", True, dbg, quad_expand\n",
    "\n",
    "def encode_png_bytes_gray(gray: np.ndarray) -> bytes:\n",
    "    ok, enc = cv2.imencode(\".png\", gray)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"PNG encoding failed (mask)\")\n",
    "    return enc.tobytes()\n",
    "\n",
    "def rounded_rect_mask(h: int, w: int, r: int) -> np.ndarray:\n",
    "    r = int(max(0, r))\n",
    "    r = min(r, min(h, w) // 2)\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    if r == 0:\n",
    "        mask[:] = 255\n",
    "        return mask\n",
    "    cv2.rectangle(mask, (r, 0), (w - r - 1, h - 1), 255, -1)\n",
    "    cv2.rectangle(mask, (0, r), (w - 1, h - r - 1), 255, -1)\n",
    "    cv2.circle(mask, (r, r), r, 255, -1)\n",
    "    cv2.circle(mask, (w - r - 1, r), r, 255, -1)\n",
    "    cv2.circle(mask, (r, h - r - 1), r, 255, -1)\n",
    "    cv2.circle(mask, (w - r - 1, h - r - 1), r, 255, -1)\n",
    "    return mask\n",
    "\n",
    "def preprocess_pil_to_proc_rgb(pil_img: Image.Image, side: str):\n",
    "    pil_fixed = ImageOps.exif_transpose(pil_img).convert(\"RGB\")\n",
    "    bgr = bgr_from_pil(pil_fixed)\n",
    "    proc_bgr, method, extracted, dbg_bgr, quad_expand = normalize_to_target(bgr, side=side, out_w=IMG_W, out_h=IMG_H)\n",
    "\n",
    "    mask = rounded_rect_mask(IMG_H, IMG_W, CORNER_RADIUS_PX)\n",
    "    if APPLY_ROUNDED_MASK_TO_IMAGE:\n",
    "        proc_bgr = cv2.bitwise_and(proc_bgr, proc_bgr, mask=mask)\n",
    "\n",
    "    proc_rgb = cv2.cvtColor(proc_bgr, cv2.COLOR_BGR2RGB)\n",
    "    dbg_rgb = cv2.cvtColor(dbg_bgr, cv2.COLOR_BGR2RGB) if dbg_bgr is not None else None\n",
    "\n",
    "    meta = {\"method\": method, \"extracted\": extracted, \"quad_expand\": float(quad_expand)}\n",
    "    return proc_rgb.astype(np.uint8), mask, dbg_rgb, meta\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Training Data Fetch (Side)\n",
    "# =========================\n",
    "def fetch_training_samples(side: str):\n",
    "    side_col = \"back_proc_bytes\" if side == \"back\" else \"front_proc_bytes\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT id, label, {side_col} AS proc_bytes\n",
    "                FROM {TABLE}\n",
    "                WHERE {side_col} IS NOT NULL AND label IS NOT NULL\n",
    "            \"\"\")\n",
    "            rows = cur.fetchall()\n",
    "\n",
    "    X, y, ids = [], [], []\n",
    "    for r in rows:\n",
    "        lbl = r[\"label\"]\n",
    "        if lbl not in LABELS:\n",
    "            continue\n",
    "        arr = proc_png_bytes_to_np(bytes(r[\"proc_bytes\"]))\n",
    "        X.append(arr)\n",
    "        y.append(LABEL2IDX[lbl])\n",
    "        ids.append(str(r[\"id\"]))\n",
    "\n",
    "    if len(X) == 0:\n",
    "        raise RuntimeError(f\"Keine Trainingsdaten gefunden f√ºr side={side} ({side_col}/label).\")\n",
    "\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    return X, y, ids\n",
    "\n",
    "def make_splits(X, y, val_ratio=0.15, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(X))\n",
    "    rng.shuffle(idx)\n",
    "    n_val = max(1, int(round(len(X)*val_ratio)))\n",
    "    val_idx = idx[:n_val]\n",
    "    tr_idx  = idx[n_val:]\n",
    "    return (X[tr_idx], y[tr_idx]), (X[val_idx], y[val_idx])\n",
    "\n",
    "def augment_tf(img):\n",
    "    img = tf.image.random_brightness(img, 0.08)\n",
    "    img = tf.image.random_contrast(img, 0.90, 1.10)\n",
    "    return img\n",
    "\n",
    "def make_ds(X, y, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(len(X), 2000), reshuffle_each_iteration=True)\n",
    "    ds = ds.map(lambda a,b: (tf.cast(a, tf.float32), b), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(lambda a,b: (augment_tf(a), b), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Model bauen/laden (+ optional trainieren) pro Side\n",
    "# =========================\n",
    "def build_model(name: str):\n",
    "    inp = keras.Input(shape=(IMG_H, IMG_W, 3), name=\"img\")\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inp)\n",
    "\n",
    "    base = keras.applications.MobileNetV2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    emb = layers.Dense(EMB_DIM, activation=None, name=\"embedding\")(x)\n",
    "    emb = layers.LayerNormalization()(emb)\n",
    "\n",
    "    out = layers.Dense(len(LABELS), activation=\"softmax\", name=\"class\")(emb)\n",
    "    return keras.Model(inp, out, name=name)\n",
    "\n",
    "def find_mobilenet_submodel(m: keras.Model):\n",
    "    for l in m.layers:\n",
    "        if isinstance(l, keras.Model) and hasattr(l, \"layers\"):\n",
    "            name = (l.name or \"\").lower()\n",
    "            if \"mobilenet\" in name and len(l.layers) > 20:\n",
    "                return l\n",
    "    return None\n",
    "\n",
    "def finetune_with_submodel(m: keras.Model, base: keras.Model, unfreeze_from_ratio=0.70):\n",
    "    base.trainable = True\n",
    "    n = len(base.layers)\n",
    "    cut = int(n * unfreeze_from_ratio)\n",
    "    for i, l in enumerate(base.layers):\n",
    "        if isinstance(l, keras.layers.BatchNormalization):\n",
    "            l.trainable = False\n",
    "        else:\n",
    "            l.trainable = (i >= cut)\n",
    "\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR_FINETUNE),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m\n",
    "\n",
    "def load_or_train_model(side: str, path: str):\n",
    "    if os.path.exists(path):\n",
    "        m = keras.models.load_model(path)\n",
    "        print(f\"‚úÖ Loaded {side} model:\", path)\n",
    "        return m\n",
    "\n",
    "    try:\n",
    "        X, y, ids = fetch_training_samples(side)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Keine Trainingsdaten f√ºr {side}. Fallback sp√§ter. Details:\", e)\n",
    "        return None\n",
    "\n",
    "    print(f\"Loaded training {side}:\", X.shape, y.shape)\n",
    "    (X_tr, y_tr), (X_va, y_va) = make_splits(X, y, val_ratio=0.15)\n",
    "    train_ds = make_ds(X_tr, y_tr, training=True)\n",
    "    val_ds   = make_ds(X_va, y_va, training=False)\n",
    "\n",
    "    # ‚úÖ Class Weights gegen Imbalance\n",
    "    cnt = Counter(y_tr.tolist())\n",
    "    present = [k for k,v in cnt.items() if v > 0]\n",
    "    cw = {k: (len(y_tr) / (len(present) * cnt[k])) for k in present}\n",
    "    print(\"Class weights:\", {IDX2LABEL[k]: round(v,3) for k,v in cw.items()})\n",
    "\n",
    "    m = build_model(name=f\"card_{side}_condition\")\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR_HEAD),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_accuracy\")]\n",
    "    m.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_HEAD, callbacks=callbacks, class_weight=cw)\n",
    "\n",
    "    base = find_mobilenet_submodel(m)\n",
    "    if base is not None:\n",
    "        finetune_with_submodel(m, base, 0.70)\n",
    "        m.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FINETUNE, callbacks=callbacks, class_weight=cw)\n",
    "\n",
    "    m.save(path)\n",
    "    print(f\"‚úÖ Saved {side} model:\", path)\n",
    "    return m\n",
    "\n",
    "model_back  = load_or_train_model(\"back\",  MODEL_PATH_BACK)\n",
    "model_front = load_or_train_model(\"front\", MODEL_PATH_FRONT)\n",
    "\n",
    "if model_back is None and model_front is None:\n",
    "    raise RuntimeError(\"Weder BACK noch FRONT Modell verf√ºgbar. Bitte Trainingsdaten speichern oder Model-Dateien bereitstellen.\")\n",
    "if model_back is None:\n",
    "    print(\"‚ö†Ô∏è BACK Modell fehlt ‚Üí nutze FRONT Modell als Fallback.\")\n",
    "    model_back = model_front\n",
    "if model_front is None:\n",
    "    print(\"‚ö†Ô∏è FRONT Modell fehlt ‚Üí nutze BACK Modell als Fallback.\")\n",
    "    model_front = model_back\n",
    "\n",
    "embedder_back  = keras.Model(inputs=model_back.input,  outputs=model_back.get_layer(\"embedding\").output,  name=\"embedder_back\")\n",
    "embedder_front = keras.Model(inputs=model_front.input, outputs=model_front.get_layer(\"embedding\").output, name=\"embedder_front\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Embedding Utils\n",
    "# =========================\n",
    "def l2_normalize(v: np.ndarray, eps=1e-12):\n",
    "    n = np.linalg.norm(v, axis=-1, keepdims=True)\n",
    "    return v / (n + eps)\n",
    "\n",
    "def embed_images_np(embedder: keras.Model, imgs_uint8: np.ndarray, batch=64) -> np.ndarray:\n",
    "    embs = []\n",
    "    for i in range(0, len(imgs_uint8), batch):\n",
    "        x = imgs_uint8[i:i+batch].astype(np.float32)\n",
    "        e = embedder.predict(x, verbose=0)\n",
    "        embs.append(e)\n",
    "    embs = np.concatenate(embs, axis=0)\n",
    "    return l2_normalize(embs)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Reference Cache (kNN) - BACK / FRONT / COMBINED\n",
    "# =========================\n",
    "REF = {\n",
    "    \"back\":     {\"emb\": None, \"meta\": None},\n",
    "    \"front\":    {\"emb\": None, \"meta\": None},\n",
    "    \"combined\": {\"emb\": None, \"meta\": None},\n",
    "}\n",
    "\n",
    "def fetch_reference_rows_side(side: str):\n",
    "    col = \"back_proc_bytes\" if side == \"back\" else \"front_proc_bytes\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT id, label, {col} AS proc_bytes, created_at\n",
    "                FROM {TABLE}\n",
    "                WHERE {col} IS NOT NULL AND label IS NOT NULL\n",
    "                ORDER BY created_at ASC\n",
    "            \"\"\")\n",
    "            return cur.fetchall()\n",
    "\n",
    "def fetch_reference_rows_combined():\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cur:\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT id, label, back_proc_bytes, front_proc_bytes, created_at\n",
    "                FROM {TABLE}\n",
    "                WHERE back_proc_bytes IS NOT NULL AND front_proc_bytes IS NOT NULL AND label IS NOT NULL\n",
    "                ORDER BY created_at ASC\n",
    "            \"\"\")\n",
    "            return cur.fetchall()\n",
    "\n",
    "def rebuild_reference_cache_side(side: str):\n",
    "    rows = fetch_reference_rows_side(side)\n",
    "    meta = []\n",
    "    emb_list = []\n",
    "    embder = embedder_back if side == \"back\" else embedder_front\n",
    "\n",
    "    ring = EMB_RING_FRAC_BACK if side == \"back\" else EMB_RING_FRAC_FRONT\n",
    "\n",
    "    for r in rows:\n",
    "        lbl = r[\"label\"]\n",
    "        if lbl not in LABELS:\n",
    "            continue\n",
    "\n",
    "        img = proc_png_bytes_to_np(bytes(r[\"proc_bytes\"]))\n",
    "        seed = seed_from_image_uint8(img)\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        views, _ = make_views(img, rng=rng)\n",
    "\n",
    "        # ‚úÖ WICHTIG: Cache-Embeddings auch nur Rand/Ecken sehen lassen\n",
    "        views_emb = [mask_center_keep_border(v, ring_frac=ring, fill=EMB_FILL_VALUE) for v in views]\n",
    "        views_np = np.stack(views_emb, axis=0)\n",
    "\n",
    "        e = embed_images_np(embder, views_np)\n",
    "        e_mean = e.mean(axis=0)\n",
    "        e_mean = e_mean / (np.linalg.norm(e_mean) + 1e-12)\n",
    "\n",
    "        emb_list.append(e_mean.astype(np.float32))\n",
    "        meta.append({\n",
    "            \"id\": str(r[\"id\"]),\n",
    "            \"label\": lbl,\n",
    "            \"proc_bytes\": bytes(r[\"proc_bytes\"]),\n",
    "            \"created_at\": r[\"created_at\"]\n",
    "        })\n",
    "\n",
    "    if len(meta) == 0:\n",
    "        REF[side][\"emb\"] = np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "        REF[side][\"meta\"] = []\n",
    "        return\n",
    "\n",
    "    REF[side][\"emb\"] = np.stack(emb_list, axis=0).astype(np.float32)\n",
    "    REF[side][\"meta\"] = meta\n",
    "\n",
    "\n",
    "def rebuild_reference_cache_combined():\n",
    "    rows = fetch_reference_rows_combined()\n",
    "    meta = []\n",
    "    emb_list = []\n",
    "\n",
    "    wb, wf = WEIGHT_BACK, WEIGHT_FRONT\n",
    "    s = wb + wf + 1e-12\n",
    "    wb, wf = wb/s, wf/s\n",
    "\n",
    "    for r in rows:\n",
    "        lbl = r[\"label\"]\n",
    "        if lbl not in LABELS:\n",
    "            continue\n",
    "\n",
    "        back_img = proc_png_bytes_to_np(bytes(r[\"back_proc_bytes\"]))\n",
    "        front_img = proc_png_bytes_to_np(bytes(r[\"front_proc_bytes\"]))\n",
    "\n",
    "        seed = seed_from_image_uint8(back_img) ^ (seed_from_image_uint8(front_img) << 1)\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        # --- BACK views ---\n",
    "        b_views, _ = make_views(back_img, rng=rng)\n",
    "        b_views_emb = [mask_center_keep_border(v, ring_frac=EMB_RING_FRAC_BACK, fill=EMB_FILL_VALUE) for v in b_views]\n",
    "        b_embs = embed_images_np(embedder_back, np.stack(b_views_emb, axis=0))\n",
    "        b_mean = b_embs.mean(axis=0)\n",
    "        b_mean = b_mean / (np.linalg.norm(b_mean) + 1e-12)\n",
    "\n",
    "        # --- FRONT views ---\n",
    "        f_views, _ = make_views(front_img, rng=rng)\n",
    "        f_views_emb = [mask_center_keep_border(v, ring_frac=EMB_RING_FRAC_FRONT, fill=EMB_FILL_VALUE) for v in f_views]\n",
    "        f_embs = embed_images_np(embedder_front, np.stack(f_views_emb, axis=0))\n",
    "        f_mean = f_embs.mean(axis=0)\n",
    "        f_mean = f_mean / (np.linalg.norm(f_mean) + 1e-12)\n",
    "\n",
    "        # --- combined mean ---\n",
    "        c_mean = wb*b_mean + wf*f_mean\n",
    "        c_mean = c_mean / (np.linalg.norm(c_mean) + 1e-12)\n",
    "\n",
    "        emb_list.append(c_mean.astype(np.float32))\n",
    "        meta.append({\n",
    "            \"id\": str(r[\"id\"]),\n",
    "            \"label\": lbl,\n",
    "            \"back_proc_bytes\": bytes(r[\"back_proc_bytes\"]),\n",
    "            \"front_proc_bytes\": bytes(r[\"front_proc_bytes\"]),\n",
    "            \"created_at\": r[\"created_at\"]\n",
    "        })\n",
    "\n",
    "    if len(meta) == 0:\n",
    "        REF[\"combined\"][\"emb\"] = np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "        REF[\"combined\"][\"meta\"] = []\n",
    "        return\n",
    "\n",
    "    REF[\"combined\"][\"emb\"] = np.stack(emb_list, axis=0).astype(np.float32)\n",
    "    REF[\"combined\"][\"meta\"] = meta\n",
    "\n",
    "\n",
    "def rebuild_all_caches():\n",
    "    rebuild_reference_cache_side(\"back\")\n",
    "    rebuild_reference_cache_side(\"front\")\n",
    "    rebuild_reference_cache_combined()\n",
    "\n",
    "# üöÄ Startup fast: Cache NICHT automatisch bauen (dauert sonst Minuten)\n",
    "REF[\"back\"][\"emb\"] = np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "REF[\"back\"][\"meta\"] = []\n",
    "REF[\"front\"][\"emb\"] = np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "REF[\"front\"][\"meta\"] = []\n",
    "REF[\"combined\"][\"emb\"] = np.zeros((0, EMB_DIM), dtype=np.float32)\n",
    "REF[\"combined\"][\"meta\"] = []\n",
    "\n",
    "print(\"‚ÑπÔ∏è Ref cache ist leer beim Start (Fast-Startup). Klicke 'üîÑ Cache neu laden', wenn du ihn brauchst.\")\n",
    "\n",
    "\n",
    "def topk_matches(cache_key: str, query_emb: np.ndarray, k=TOPK):\n",
    "    emb = REF[cache_key][\"emb\"]\n",
    "    meta = REF[cache_key][\"meta\"]\n",
    "    if emb is None or len(emb) == 0:\n",
    "        return [], []\n",
    "    sims = emb @ query_emb\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return idx.tolist(), sims[idx].tolist()\n",
    "\n",
    "def knn_vote(cache_key: str, idxs, sims):\n",
    "    meta = REF[cache_key][\"meta\"]\n",
    "    scores = {l: 0.0 for l in LABELS}\n",
    "    for i, s in list(zip(idxs, sims))[:KNN_K]:\n",
    "        scores[meta[i][\"label\"]] += float(max(0.0, s))\n",
    "    best_lbl, best_score = max(scores.items(), key=lambda x: x[1])\n",
    "    total = sum(scores.values()) + 1e-12\n",
    "    conf = best_score / total\n",
    "    return best_lbl, float(conf), scores\n",
    "\n",
    "def local_prior_probs_from_neighbors(cache_key: str, idxs: list, sims: list,\n",
    "                                     power: float = 3.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Baut aus den (idxs,sims) eine lokale Klassenverteilung p(label|neighbors).\n",
    "    Weighting: w_i = max(0, sim_i)^power\n",
    "    \"\"\"\n",
    "    p = np.zeros((len(LABELS),), dtype=np.float32)\n",
    "    meta = REF[cache_key][\"meta\"] or []\n",
    "    if not idxs or not sims or not meta:\n",
    "        return p\n",
    "\n",
    "    for i, s in zip(idxs, sims):\n",
    "        if i < 0 or i >= len(meta):\n",
    "            continue\n",
    "        lbl = meta[i].get(\"label\")\n",
    "        if lbl not in LABEL2IDX:\n",
    "            continue\n",
    "        w = max(0.0, float(s)) ** float(power)\n",
    "        p[LABEL2IDX[lbl]] += float(w)\n",
    "\n",
    "    ssum = float(p.sum())\n",
    "    if ssum <= 1e-12:\n",
    "        return p\n",
    "    return (p / ssum).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Analyse + Robust Aggregation + Combined\n",
    "# =========================\n",
    "def probs_from_knn_scores(scores: dict) -> np.ndarray:\n",
    "    p = np.zeros((len(LABELS),), dtype=np.float32)\n",
    "    if not scores:\n",
    "        return p\n",
    "    for l, v in scores.items():\n",
    "        if l in LABEL_IDX:\n",
    "            p[LABEL_IDX[l]] = max(0.0, float(v))\n",
    "    s = float(p.sum())\n",
    "    if s <= 1e-12:\n",
    "        return p\n",
    "    return (p / s).astype(np.float32)\n",
    "\n",
    "def effective_side_probs(status_side: dict, probs_side: np.ndarray) -> np.ndarray:\n",
    "    probs_side = np.asarray(probs_side, dtype=np.float32)\n",
    "    probs_side = probs_side / (float(probs_side.sum()) + 1e-12)\n",
    "\n",
    "    cls_conf = float((status_side.get(\"classifier\") or {}).get(\"conf\", 0.0))\n",
    "    knn = status_side.get(\"knn\") or {}\n",
    "    knn_scores = knn.get(\"scores\", {}) or {}\n",
    "    best_sim = float(knn.get(\"best_sim\", 0.0))\n",
    "\n",
    "    if best_sim < KNN_MIX_MIN_BEST_SIM:\n",
    "        return probs_side\n",
    "\n",
    "    p_knn = probs_from_knn_scores(knn_scores)\n",
    "    mix = KNN_MIX_BASE * max(0.0, (0.80 - cls_conf) / 0.80)\n",
    "    mix = float(np.clip(mix, 0.0, 0.35))\n",
    "\n",
    "    if p_knn.sum() <= 1e-12 or mix <= 1e-6:\n",
    "        return probs_side\n",
    "\n",
    "    p = (1.0 - mix) * probs_side + mix * p_knn\n",
    "    p = p / (float(p.sum()) + 1e-12)\n",
    "    return p.astype(np.float32)\n",
    "\n",
    "def expected_index_from_probs(probs: np.ndarray) -> float:\n",
    "    p = np.asarray(probs, dtype=np.float32)\n",
    "    p = p / (float(p.sum()) + 1e-12)\n",
    "    idx = np.arange(len(LABELS), dtype=np.float32)\n",
    "    return float(np.sum(idx * p))\n",
    "\n",
    "def label_from_expected_idx(idx: float) -> str:\n",
    "    i = int(np.clip(int(round(idx)), 0, len(LABELS)-1))\n",
    "    return IDX2LABEL[i]\n",
    "\n",
    "def aggregate_probs_robust(probs_v: np.ndarray, trim_q: float = VIEW_TRIM_Q) -> Tuple[np.ndarray, dict]:\n",
    "    pv = np.asarray(probs_v, dtype=np.float32)\n",
    "    pv = pv / (pv.sum(axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    sev = np.sum(pv * np.arange(len(LABELS), dtype=np.float32)[None, :], axis=1)\n",
    "    lo = float(np.quantile(sev, trim_q))\n",
    "    hi = float(np.quantile(sev, 1.0 - trim_q))\n",
    "    keep = (sev >= lo) & (sev <= hi)\n",
    "\n",
    "    if int(keep.sum()) < max(3, int(0.5 * len(sev))):\n",
    "        keep[:] = True\n",
    "\n",
    "    p = pv[keep].mean(axis=0)\n",
    "    p = p / (float(p.sum()) + 1e-12)\n",
    "    meta = {\"views_total\": int(len(sev)), \"views_kept\": int(keep.sum()), \"sev_median\": float(np.median(sev))}\n",
    "    return p.astype(np.float32), meta\n",
    "\n",
    "def guardrail_label(candidate_label: str, probs: np.ndarray, cls_conf: float, best_sim: float, knn_conf: float) -> Tuple[str, str]:\n",
    "    idx_exp = expected_index_from_probs(probs)\n",
    "    lbl_exp = label_from_expected_idx(idx_exp)\n",
    "\n",
    "    diff = abs(LABEL2IDX[candidate_label] - LABEL2IDX[lbl_exp])\n",
    "    strong = (cls_conf >= EXTREME_ALLOW_CNN_CONF) or (best_sim >= EXTREME_ALLOW_SIM and knn_conf >= EXTREME_ALLOW_KNN_CONF)\n",
    "\n",
    "    if diff > MAX_OUTLIER_JUMP and not strong:\n",
    "        return lbl_exp, f\"Guardrail(exp={lbl_exp}, idx={idx_exp:.2f}, diff={diff})\"\n",
    "    return candidate_label, \"\"\n",
    "\n",
    "def analyze_once(side: str, proc_np_uint8: np.ndarray, rng: np.random.Generator):\n",
    "    proc_np_uint8 = resize_to_base(proc_np_uint8)\n",
    "\n",
    "    model = model_back if side == \"back\" else model_front\n",
    "    embder = embedder_back if side == \"back\" else embedder_front\n",
    "\n",
    "    views, _ = make_views(proc_np_uint8, rng=rng)\n",
    "    views_np = np.stack([(infer_augment_np(v, rng) if INFER_AUG else v.astype(np.float32)) for v in views], axis=0)\n",
    "\n",
    "    probs_v = model.predict(views_np, verbose=0)\n",
    "    probs, agg_meta = aggregate_probs_robust(probs_v, trim_q=VIEW_TRIM_Q)\n",
    "\n",
    "    cls_idx = int(np.argmax(probs))\n",
    "    cls_label = IDX2LABEL[cls_idx]\n",
    "    cls_conf = float(probs[cls_idx])\n",
    "\n",
    "    ring = EMB_RING_FRAC_BACK if side == \"back\" else EMB_RING_FRAC_FRONT\n",
    "    views_emb = [mask_center_keep_border(v, ring_frac=ring, fill=EMB_FILL_VALUE) for v in views]\n",
    "    e = embed_images_np(embder, np.stack(views_emb, axis=0))\n",
    "\n",
    "    q_emb = e.mean(axis=0)\n",
    "    q_emb = q_emb / (np.linalg.norm(q_emb) + 1e-12)\n",
    "\n",
    "    idxs, sims = topk_matches(side, q_emb, k=TOPK)\n",
    "    best_sim = float(sims[0]) if sims else 0.0\n",
    "\n",
    "    if idxs:\n",
    "        knn_label, knn_conf, knn_scores = knn_vote(side, idxs, sims)\n",
    "    else:\n",
    "        knn_label, knn_conf, knn_scores = cls_label, 0.0, {}\n",
    "\n",
    "    use_knn_override = (\n",
    "        USE_KNN_FUSION and\n",
    "        cls_conf < FUSION_CONF_TH and\n",
    "        best_sim >= KNN_FUSION_MIN_BEST_SIM and\n",
    "        float(knn_conf) >= KNN_FUSION_MIN_CONF\n",
    "    )\n",
    "\n",
    "    if use_knn_override:\n",
    "        candidate = knn_label\n",
    "        final_source = f\"kNN override (conf<{FUSION_CONF_TH}, sim={best_sim:.3f})\"\n",
    "    else:\n",
    "        candidate = cls_label\n",
    "        final_source = \"Classifier\"\n",
    "\n",
    "    final_label, gr_note = guardrail_label(candidate, probs, cls_conf, best_sim, float(knn_conf))\n",
    "    if gr_note:\n",
    "        final_source = final_source + \" + \" + gr_note\n",
    "\n",
    "    return {\n",
    "        \"final_label\": final_label,\n",
    "        \"final_source\": final_source,\n",
    "        \"cls_label\": cls_label,\n",
    "        \"cls_conf\": cls_conf,\n",
    "        \"probs\": probs,\n",
    "        \"q_emb\": q_emb,\n",
    "        \"knn_label\": knn_label,\n",
    "        \"knn_conf\": knn_conf,\n",
    "        \"knn_scores\": knn_scores,\n",
    "        \"best_sim\": best_sim,\n",
    "        \"idxs\": idxs,\n",
    "        \"sims\": sims,\n",
    "        \"agg_meta\": agg_meta\n",
    "    }\n",
    "\n",
    "# --- PSA Scale (inkl. 1.5) ---\n",
    "PSA_SCALE = {\n",
    "    10.0: (\"GEM-MT\", \"nahezu perfekt\"),\n",
    "    9.0:  (\"MINT\",   \"superb, nur minimale M√§ngel\"),\n",
    "    8.0:  (\"NM-MT\",  \"fast mint, kleine Unsauberkeiten bei genauer Pr√ºfung\"),\n",
    "    7.0:  (\"NM\",     \"leichte Abnutzung sichtbar (bei genauer Pr√ºfung)\"),\n",
    "    6.0:  (\"EX-MT\",  \"sichtbare Abnutzung/kleiner Druckfehler m√∂glich\"),\n",
    "    5.0:  (\"EX\",     \"mehr sichtbare Wear, evtl. kleine Chips/leichte Kratzer\"),\n",
    "    4.0:  (\"VG-EX\",  \"moderater Wear, ggf. leichter Knick\"),\n",
    "    3.0:  (\"VG\",     \"deutlicher Wear, Knick(e) m√∂glich\"),\n",
    "    2.0:  (\"GOOD\",   \"starker Wear, mehrere Knicke m√∂glich\"),\n",
    "    1.5:  (\"FR\",     \"extrem abgenutzt, muss aber ‚Äûintakt‚Äú sein\"),\n",
    "    1.0:  (\"PR\",     \"sehr starker Schaden, Eye-Appeal nahezu weg\"),\n",
    "}\n",
    "\n",
    "def psa_round_grade(g: float) -> float:\n",
    "    \"\"\"\n",
    "    PSA: grunds√§tzlich ganze Zahlen, au√üer 1.5.\n",
    "    => <2.0 auf 0.5er Schritte runden, sonst auf ganze Zahl.\n",
    "    \"\"\"\n",
    "    g = float(max(1.0, min(10.0, g)))\n",
    "    if g < 2.0:\n",
    "        return round(g * 2.0) / 2.0\n",
    "    return float(int(round(g)))\n",
    "\n",
    "def format_grade(g: float) -> str:\n",
    "    g = float(g)\n",
    "    if abs(g - int(g)) < 1e-9:\n",
    "        return str(int(g))\n",
    "    return f\"{g:.1f}\".rstrip(\"0\").rstrip(\".\")\n",
    "\n",
    "def psa_line(g: float) -> str:\n",
    "    g = psa_round_grade(g)\n",
    "    abbr, desc = PSA_SCALE.get(g, (\"?\", \"\"))\n",
    "    return f\"PSA {format_grade(g)} ‚Äì {abbr}: {desc}\"\n",
    "\n",
    "\n",
    "# Deine Klassen -> PSA-Grade-Ranges (wie bisher, aber PO erlaubt jetzt 1.5)\n",
    "GRADE_RANGES = {\n",
    "    \"NM\": (9.0, 10.0),\n",
    "    \"EX\": (7.0, 8.0),\n",
    "    \"GD\": (5.0, 6.0),\n",
    "    \"LP\": (3.0, 4.0),\n",
    "    \"PL\": (2.0, 2.0),\n",
    "    \"PO\": (1.0, 1.5),   # ‚úÖ neu: 1 oder 1.5\n",
    "}\n",
    "\n",
    "\n",
    "def compute_grade_1to10(final_label: str, probs: np.ndarray, knn_conf: float, sims: list):\n",
    "    lo, hi = GRADE_RANGES.get(final_label, (1.0, 10.0))\n",
    "\n",
    "    p_sorted = np.sort(probs)[::-1]\n",
    "    p1 = float(p_sorted[0]) if len(p_sorted) else 0.0\n",
    "    p2 = float(p_sorted[1]) if len(p_sorted) > 1 else 0.0\n",
    "    margin = max(0.0, p1 - p2)\n",
    "\n",
    "    sim_strength = float(np.mean(sims[:min(5, len(sims))])) if sims else 0.0\n",
    "    sim_strength = max(0.0, min(1.0, sim_strength))\n",
    "\n",
    "    score = 0.55*p1 + 0.25*margin + 0.12*float(knn_conf) + 0.08*sim_strength\n",
    "    score = max(0.0, min(1.0, score))\n",
    "\n",
    "    # continuous grade within label-range\n",
    "    if abs(hi - lo) < 1e-9:\n",
    "        g_cont = lo\n",
    "    else:\n",
    "        g_cont = lo + (hi - lo) * score\n",
    "\n",
    "    # PSA rounding rule\n",
    "    g = psa_round_grade(g_cont)\n",
    "\n",
    "    # clamp to range (wichtig f√ºr PO: 1..1.5)\n",
    "    g = max(lo, min(hi, g))\n",
    "\n",
    "    meta = {\n",
    "        \"score\": round(score, 4),\n",
    "        \"p1\": round(p1, 4),\n",
    "        \"margin\": round(margin, 4),\n",
    "        \"knn_conf\": round(float(knn_conf), 4),\n",
    "        \"sim_strength\": round(sim_strength, 4),\n",
    "        \"grade_cont\": round(float(g_cont), 4),\n",
    "        \"grade_psa\": format_grade(g),\n",
    "        \"psa\": psa_line(g),\n",
    "    }\n",
    "    return float(g), meta\n",
    "\n",
    "\n",
    "def pregrading_text(label: str, grade_1to10: float):\n",
    "    tips = {\n",
    "        \"NM\": \"Sehr guter Kandidat f√ºr Grading. Pr√ºfe Whitening an Ecken/Kanten + feine Kratzer im Licht.\",\n",
    "        \"EX\": \"Guter Kandidat. Kleine M√§ngel wahrscheinlich (Whitening/leichte Lines).\",\n",
    "        \"GD\": \"Mittelzustand. Grading lohnt sich meist nur bei hochpreisigen Karten.\",\n",
    "        \"LP\": \"Deutlich bespielt. Grading eher zur Dokumentation/bei Seltenheit.\",\n",
    "        \"PL\": \"Stark bespielt. Grading selten wirtschaftlich.\",\n",
    "        \"PO\": \"Besch√§digt. Grading meist nicht wirtschaftlich (au√üer sehr selten).\"\n",
    "    }\n",
    "    g = psa_round_grade(float(grade_1to10))\n",
    "    return (\n",
    "        f\"Pregrading (TCG-Klasse): {label} | Grade: {format_grade(g)}/10\\n\"\n",
    "        f\"{psa_line(g)}\\n\"\n",
    "        + tips.get(label, \"\")\n",
    "    )\n",
    "\n",
    "\n",
    "def label_from_grade_1to10(g: float) -> str:\n",
    "    g = float(max(1.0, min(10.0, g)))\n",
    "    if g >= 9.0:\n",
    "        return \"NM\"\n",
    "    if g >= 7.0:\n",
    "        return \"EX\"\n",
    "    if g >= 5.0:\n",
    "        return \"GD\"\n",
    "    if g >= 3.0:\n",
    "        return \"LP\"\n",
    "    if g >= 2.0:\n",
    "        return \"PL\"\n",
    "    return \"PO\"\n",
    "\n",
    "\n",
    "\n",
    "def analyze_ensemble(side: str, proc_np_uint8: np.ndarray, n_runs: int = ENSEMBLE_RUNS):\n",
    "    proc_np_uint8 = resize_to_base(proc_np_uint8)\n",
    "    base_seed = seed_from_image_uint8(proc_np_uint8) if DETERMINISTIC_PER_IMAGE else int(np.random.default_rng().integers(0, 2**32-1))\n",
    "\n",
    "    runs = []\n",
    "    probs_list = []\n",
    "    emb_list = []\n",
    "    label_counts = {l: 0 for l in LABELS}\n",
    "    grades = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        rng = np.random.default_rng(base_seed + i * SEED_STEP)\n",
    "        r = analyze_once(side, proc_np_uint8, rng=rng)\n",
    "        runs.append(r)\n",
    "        probs_list.append(r[\"probs\"])\n",
    "        emb_list.append(r[\"q_emb\"])\n",
    "        if r[\"final_label\"] in label_counts:\n",
    "            label_counts[r[\"final_label\"]] += 1\n",
    "        g, _ = compute_grade_1to10(r[\"final_label\"], r[\"probs\"], r[\"knn_conf\"], r[\"sims\"])\n",
    "        grades.append(g)\n",
    "\n",
    "    best_label = max(label_counts.items(), key=lambda kv: kv[1])[0]\n",
    "    best_count = label_counts[best_label]\n",
    "    tied = [l for l,cnt in label_counts.items() if cnt == best_count]\n",
    "\n",
    "    probs_avg = np.mean(np.stack(probs_list, axis=0), axis=0)\n",
    "    probs_avg = probs_avg / (probs_avg.sum() + 1e-12)\n",
    "\n",
    "    q_emb_avg = np.mean(np.stack(emb_list, axis=0), axis=0)\n",
    "    q_emb_avg = q_emb_avg / (np.linalg.norm(q_emb_avg) + 1e-12)\n",
    "\n",
    "    idxs, sims = topk_matches(side, q_emb_avg, k=TOPK)\n",
    "    best_sim = float(sims[0]) if sims else 0.0\n",
    "\n",
    "    if idxs:\n",
    "        knn_label, knn_conf, knn_scores = knn_vote(side, idxs, sims)\n",
    "    else:\n",
    "        knn_label, knn_conf, knn_scores = IDX2LABEL[int(np.argmax(probs_avg))], 0.0, {}\n",
    "\n",
    "    cls_idx = int(np.argmax(probs_avg))\n",
    "    cls_label = IDX2LABEL[cls_idx]\n",
    "    cls_conf = float(probs_avg[cls_idx])\n",
    "\n",
    "    if USE_KNN_FUSION and cls_conf < FUSION_CONF_TH and best_sim >= KNN_FUSION_MIN_BEST_SIM and float(knn_conf) >= KNN_FUSION_MIN_CONF:\n",
    "        agg_final_label = knn_label\n",
    "        agg_source = f\"kNN (cls_conf<{FUSION_CONF_TH}, sim={best_sim:.3f})\"\n",
    "    else:\n",
    "        agg_final_label = cls_label\n",
    "        agg_source = \"Classifier\"\n",
    "\n",
    "    if len(tied) == 1:\n",
    "        final_label = best_label\n",
    "        final_source = f\"Ensemble majority ({best_count}/{n_runs})\"\n",
    "    else:\n",
    "        final_label = agg_final_label\n",
    "        final_source = f\"Ensemble tie-break ‚Üí {agg_source} (ties={tied})\"\n",
    "\n",
    "    grades_for_label = [g for g, r in zip(grades, runs) if r[\"final_label\"] == final_label]\n",
    "    if grades_for_label:\n",
    "        final_grade = psa_round_grade(float(np.median(np.array(grades_for_label))))\n",
    "        grade_meta = {\"method\": \"median_over_majority_runs\", \"n\": len(grades_for_label)}\n",
    "    else:\n",
    "        final_grade, gm = compute_grade_1to10(final_label, probs_avg, knn_conf, sims)\n",
    "        grade_meta = {\"method\": \"aggregated_fallback\", **gm}\n",
    "\n",
    "    gal = []\n",
    "    meta = REF[side][\"meta\"]\n",
    "    for i, s in zip(idxs, sims):\n",
    "        m = meta[i]\n",
    "        img = Image.open(io.BytesIO(m[\"proc_bytes\"])).convert(\"RGB\")\n",
    "        cap = f'{m[\"label\"]} | sim={s:.3f} | {m[\"id\"][:8]}'\n",
    "        gal.append((img, cap))\n",
    "\n",
    "    topk_list = [{\"label\": meta[i][\"label\"], \"sim\": float(s), \"id\": meta[i][\"id\"]} for i, s in zip(idxs, sims)]\n",
    "\n",
    "    status = {\n",
    "        \"side\": side,\n",
    "        \"final_label\": final_label,\n",
    "        \"final_source\": final_source,\n",
    "        \"grade\": float(final_grade),\n",
    "        \"classifier\": {\n",
    "            \"label\": cls_label,\n",
    "            \"conf\": round(cls_conf, 4),\n",
    "            \"probs\": {IDX2LABEL[i]: float(probs_avg[i]) for i in range(len(LABELS))}\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"label\": knn_label,\n",
    "            \"conf\": round(float(knn_conf), 4),\n",
    "            \"best_sim\": round(float(best_sim), 4),\n",
    "            \"scores\": {k: round(float(v), 4) for k, v in (knn_scores or {}).items()}\n",
    "        },\n",
    "        \"views_used\": len(make_views(proc_np_uint8, rng=np.random.default_rng(base_seed))[0]),\n",
    "        \"reference_size\": len(meta),\n",
    "        \"topk\": topk_list,\n",
    "        \"ensemble\": {\n",
    "            \"runs\": n_runs,\n",
    "            \"deterministic_per_image\": bool(DETERMINISTIC_PER_IMAGE),\n",
    "            \"seed\": int(base_seed),\n",
    "            \"label_counts\": label_counts,\n",
    "            \"grades\": grades\n",
    "        }\n",
    "    }\n",
    "\n",
    "    txt = (\n",
    "        f\"{side.upper()}: {final_label} | Grade {format_grade(final_grade)}/10 | {psa_line(final_grade)} | {final_source} | \"\n",
    "        f\"CNN: {cls_label} ({cls_conf:.2f}) | kNN: {knn_label} ({knn_conf:.2f}, sim={best_sim:.2f}) | \"\n",
    "        f\"Votes: {label_counts}\"\n",
    "    )\n",
    "\n",
    "    state_payload = {\"status\": status, \"q_emb\": q_emb_avg}\n",
    "    return status, gal, state_payload, txt, probs_avg, idxs, sims, final_grade, grade_meta\n",
    "\n",
    "def compute_combined(\n",
    "    status_b, probs_b, sims_b, st_b, grade_b, grade_meta_b,\n",
    "    status_f, probs_f, sims_f, st_f, grade_f, grade_meta_f\n",
    "):\n",
    "\n",
    "    wb, wf = WEIGHT_BACK, WEIGHT_FRONT\n",
    "    s = wb + wf + 1e-12\n",
    "    wb, wf = wb/s, wf/s\n",
    "\n",
    "    # --- Side probs (evtl. schon leicht mit Side-kNN gemischt) ---\n",
    "    p_b = effective_side_probs(status_b, probs_b)\n",
    "    p_f = effective_side_probs(status_f, probs_f)\n",
    "\n",
    "    # --- Raw CNN Combined ---\n",
    "    p_c_raw = wb*p_b + wf*p_f\n",
    "    p_c_raw = p_c_raw / (float(p_c_raw.sum()) + 1e-12)\n",
    "\n",
    "    # --- Combined embedding ---\n",
    "    q_b = st_b.get(\"q_emb\")\n",
    "    q_f = st_f.get(\"q_emb\")\n",
    "    if q_b is not None and q_f is not None:\n",
    "        q_c = wb*q_b + wf*q_f\n",
    "        q_c = q_c / (np.linalg.norm(q_c) + 1e-12)\n",
    "    else:\n",
    "        q_c = q_b if q_b is not None else q_f\n",
    "\n",
    "    # --- Combined retrieval (Top-10) + kNN vote ---\n",
    "    idxs_c, sims_c = ([], [])\n",
    "    knn_c_label, knn_c_conf, knn_c_scores, best_sim_c = None, 0.0, {}, 0.0\n",
    "\n",
    "    if q_c is not None:\n",
    "        idxs_c, sims_c = topk_matches(\"combined\", q_c, k=TOPK)\n",
    "        best_sim_c = float(sims_c[0]) if sims_c else 0.0\n",
    "\n",
    "        if idxs_c:\n",
    "            knn_c_label, knn_c_conf, knn_c_scores = knn_vote(\"combined\", idxs_c, sims_c)\n",
    "        else:\n",
    "            knn_c_label, knn_c_conf, knn_c_scores = IDX2LABEL[int(np.argmax(p_c_raw))], 0.0, {}\n",
    "    else:\n",
    "        knn_c_label, knn_c_conf, knn_c_scores = IDX2LABEL[int(np.argmax(p_c_raw))], 0.0, {}\n",
    "\n",
    "    # --- Local Neighbor Prior (Top-10) ‚Üí fuse in combined probs ---\n",
    "    p_c = p_c_raw.copy().astype(np.float32)\n",
    "    local_mix = 0.0\n",
    "    p_local = np.zeros_like(p_c, dtype=np.float32)\n",
    "\n",
    "    if USE_LOCAL_TOP10 and q_c is not None and idxs_c and (best_sim_c >= LOCAL_MIN_SIM_FOR_MIX):\n",
    "        p_local = local_prior_probs_from_neighbors(\n",
    "            \"combined\",\n",
    "            idxs_c[:LOCAL_TOPK],\n",
    "            sims_c[:LOCAL_TOPK],\n",
    "            power=LOCAL_PRIOR_POWER\n",
    "        )\n",
    "\n",
    "        t = (best_sim_c - LOCAL_MIN_SIM_FOR_MIX) / (1.0 - LOCAL_MIN_SIM_FOR_MIX + 1e-12)\n",
    "        t = float(np.clip(t, 0.0, 1.0))\n",
    "        local_mix = float(LOCAL_MAX_MIX * t)\n",
    "\n",
    "        if float(p_local.sum()) > 1e-12 and local_mix > 1e-6:\n",
    "            p_c = (1.0 - local_mix) * p_c + local_mix * p_local\n",
    "            p_c = p_c / (float(p_c.sum()) + 1e-12)\n",
    "\n",
    "    # --- Labels (Back/Front) ---\n",
    "    back_label  = status_b.get(\"final_label\", \"?\")\n",
    "    front_label = status_f.get(\"final_label\", \"?\")\n",
    "    diff_lbl = abs(LABEL2IDX.get(back_label, 0) - LABEL2IDX.get(front_label, 0))\n",
    "\n",
    "    # --- Final decision logic ---\n",
    "    if COMBINED_TIEBREAK_BY_KNN and back_label != front_label:\n",
    "        if diff_lbl >= DISAGREE_HARD_DIFF:\n",
    "            if (best_sim_c >= DISAGREE_REQUIRE_SIM) and (float(knn_c_conf) >= DISAGREE_REQUIRE_CONF) and (knn_c_label in (back_label, front_label)):\n",
    "                final_label = knn_c_label\n",
    "                final_source = f\"DISAGREE hard(diff={diff_lbl}) ‚Üí Combined kNN (lbl={knn_c_label}, conf={knn_c_conf:.2f}, sim={best_sim_c:.2f})\"\n",
    "            else:\n",
    "                idx_pick = int(np.argmax(p_c))\n",
    "                lo = min(LABEL2IDX[back_label], LABEL2IDX[front_label])\n",
    "                hi = max(LABEL2IDX[back_label], LABEL2IDX[front_label])\n",
    "                idx_pick = int(np.clip(idx_pick, lo, hi))\n",
    "                final_label = IDX2LABEL[idx_pick]\n",
    "                final_source = f\"DISAGREE hard(diff={diff_lbl}) ‚Üí Clamp fused combined probs to [{IDX2LABEL[lo]}..{IDX2LABEL[hi]}]\"\n",
    "        else:\n",
    "            if knn_c_label in (back_label, front_label) and best_sim_c >= KNN_MIX_MIN_BEST_SIM:\n",
    "                final_label = knn_c_label\n",
    "                final_source = f\"DISAGREE ‚Üí Combined kNN tie-break (lbl={knn_c_label}, conf={knn_c_conf:.2f}, sim={best_sim_c:.2f})\"\n",
    "            else:\n",
    "                cb = float((status_b.get(\"classifier\") or {}).get(\"conf\", 0.0))\n",
    "                cf = float((status_f.get(\"classifier\") or {}).get(\"conf\", 0.0))\n",
    "                sb = float((status_b.get(\"knn\") or {}).get(\"best_sim\", 0.0))\n",
    "                sf = float((status_f.get(\"knn\") or {}).get(\"best_sim\", 0.0))\n",
    "                score_b = 0.65*cb + 0.35*sb\n",
    "                score_f = 0.65*cf + 0.35*sf\n",
    "                if score_f > score_b:\n",
    "                    final_label = front_label\n",
    "                    final_source = f\"DISAGREE ‚Üí evidence pick FRONT (score_f={score_f:.2f} > score_b={score_b:.2f})\"\n",
    "                else:\n",
    "                    final_label = back_label\n",
    "                    final_source = f\"DISAGREE ‚Üí evidence pick BACK (score_b={score_b:.2f} >= score_f={score_f:.2f})\"\n",
    "    else:\n",
    "        final_label = IDX2LABEL[int(np.argmax(p_c))]\n",
    "        final_source = \"AGREE/Combined fused probs\"\n",
    "\n",
    "    # --- Grade auf fused p_c (Model-Grade) ---\n",
    "    sims_for_grade = sims_c[:5] if sims_c else []\n",
    "    grade_c_model, grade_meta_c = compute_grade_1to10(final_label, p_c, float(knn_c_conf), sims_for_grade)\n",
    "\n",
    "    # ‚úÖ Disagree-Guardrail: Wenn Back != Front ‚Üí Grade = Median(side grades) & Label passend zum Grade\n",
    "    if back_label != front_label:\n",
    "        grade_c = psa_round_grade(float(np.median([float(grade_b), float(grade_f)])))\n",
    "        grade_c = max(1, min(10, grade_c))\n",
    "        final_label = label_from_grade_1to10(grade_c)\n",
    "        final_source = f\"{final_source} + GradeGuard(median(back={grade_b}, front={grade_f}))\"\n",
    "        grade_meta_c = {\n",
    "            \"method\": \"median_side_grades_due_to_disagree\",\n",
    "            \"grade_b\": int(grade_b),\n",
    "            \"grade_f\": int(grade_f),\n",
    "            \"grade_model\": int(grade_c_model),\n",
    "        }\n",
    "    else:\n",
    "        grade_c = int(grade_c_model)\n",
    "        grade_meta_c.update({\n",
    "            \"w_back\": round(float(wb), 3),\n",
    "            \"w_front\": round(float(wf), 3),\n",
    "            \"tiebreak_by_knn\": bool(COMBINED_TIEBREAK_BY_KNN),\n",
    "            \"combined_knn_best_sim\": round(float(best_sim_c), 3),\n",
    "            \"combined_knn_conf\": round(float(knn_c_conf), 3),\n",
    "            \"local_mix\": round(float(local_mix), 4),\n",
    "            \"local_min_sim_for_mix\": float(LOCAL_MIN_SIM_FOR_MIX),\n",
    "            \"local_topk\": int(LOCAL_TOPK),\n",
    "            \"local_prior_power\": float(LOCAL_PRIOR_POWER),\n",
    "        })\n",
    "\n",
    "    # --- TopK Meta ---\n",
    "    meta_c = REF[\"combined\"][\"meta\"] or []\n",
    "    topk_c = [{\"label\": meta_c[i][\"label\"], \"sim\": float(s), \"id\": meta_c[i][\"id\"]} for i, s in zip(idxs_c, sims_c)]\n",
    "\n",
    "    # --- Status ---\n",
    "    status_c = {\n",
    "        \"side\": \"combined\",\n",
    "        \"final_label\": final_label,\n",
    "        \"final_source\": final_source,\n",
    "        \"weights\": {\"back\": round(float(wb), 4), \"front\": round(float(wf), 4)},\n",
    "        \"grade\": int(grade_c),\n",
    "\n",
    "        \"cnn_raw\": {\n",
    "            \"label\": IDX2LABEL[int(np.argmax(p_c_raw))],\n",
    "            \"conf\": round(float(np.max(p_c_raw)), 4),\n",
    "            \"probs\": {IDX2LABEL[i]: float(p_c_raw[i]) for i in range(len(LABELS))}\n",
    "        },\n",
    "\n",
    "        \"classifier\": {\n",
    "            \"label\": IDX2LABEL[int(np.argmax(p_c))],\n",
    "            \"conf\": round(float(np.max(p_c)), 4),\n",
    "            \"probs\": {IDX2LABEL[i]: float(p_c[i]) for i in range(len(LABELS))}\n",
    "        },\n",
    "\n",
    "        \"knn\": {\n",
    "            \"label\": knn_c_label,\n",
    "            \"conf\": round(float(knn_c_conf), 4),\n",
    "            \"best_sim\": round(float(best_sim_c), 4),\n",
    "            \"scores\": {k: round(float(v), 4) for k, v in (knn_c_scores or {}).items()}\n",
    "        },\n",
    "\n",
    "        \"local_retrieval\": {\n",
    "            \"enabled\": bool(USE_LOCAL_TOP10),\n",
    "            \"local_mix\": round(float(local_mix), 4),\n",
    "            \"best_sim\": round(float(best_sim_c), 4),\n",
    "            \"min_sim_for_mix\": float(LOCAL_MIN_SIM_FOR_MIX),\n",
    "            \"topk\": int(LOCAL_TOPK),\n",
    "        },\n",
    "\n",
    "        \"topk\": topk_c,\n",
    "        \"back\": {\"label\": back_label, \"grade\": int(grade_b)},\n",
    "        \"front\": {\"label\": front_label, \"grade\": int(grade_f)},\n",
    "    }\n",
    "\n",
    "    state_c = {\"status\": status_c, \"q_emb\": q_c}\n",
    "    return status_c, p_c, state_c, grade_c, grade_meta_c\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DB Insert (FRONT+BACK Pflicht) + Approve Save\n",
    "# =========================\n",
    "def insert_sample_fb(\n",
    "    label, note,\n",
    "    back_raw_bytes, back_raw_format, back_raw_w, back_raw_h,\n",
    "    back_proc_bytes, back_proc_format, back_proc_w, back_proc_h,\n",
    "    back_mask_bytes, back_mask_format=\"png\", back_mask_w=IMG_W, back_mask_h=IMG_H,\n",
    "    back_proc_method=None, back_proc_quad_expand=None,\n",
    "    front_raw_bytes=None, front_raw_format=\"jpeg\", front_raw_w=None, front_raw_h=None,\n",
    "    front_proc_bytes=None, front_proc_format=\"png\", front_proc_w=IMG_W, front_proc_h=IMG_H,\n",
    "    front_mask_bytes=None, front_mask_format=\"png\", front_mask_w=IMG_W, front_mask_h=IMG_H,\n",
    "    front_proc_method=None, front_proc_quad_expand=None,\n",
    "):\n",
    "    if front_raw_bytes is None or front_proc_bytes is None:\n",
    "        raise ValueError(\"Front ist Pflicht (raw/proc).\")\n",
    "\n",
    "    back_sha  = hashlib.sha256(back_raw_bytes).hexdigest()\n",
    "    front_sha = hashlib.sha256(front_raw_bytes).hexdigest()\n",
    "    sample_id = uuid.uuid4()\n",
    "\n",
    "    try:\n",
    "        with get_conn() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(f\"\"\"\n",
    "                    INSERT INTO {TABLE} (\n",
    "                        id, label, note,\n",
    "\n",
    "                        back_raw_sha256, back_raw_format, back_raw_w, back_raw_h, back_raw_bytes,\n",
    "                        back_proc_format, back_proc_w, back_proc_h, back_proc_bytes,\n",
    "                        back_proc_mask_format, back_proc_mask_w, back_proc_mask_h, back_proc_mask_bytes,\n",
    "                        back_proc_method, back_proc_quad_expand,\n",
    "\n",
    "                        front_raw_sha256, front_raw_format, front_raw_w, front_raw_h, front_raw_bytes,\n",
    "                        front_proc_format, front_proc_w, front_proc_h, front_proc_bytes,\n",
    "                        front_proc_mask_format, front_proc_mask_w, front_proc_mask_h, front_proc_mask_bytes,\n",
    "                        front_proc_method, front_proc_quad_expand\n",
    "                    )\n",
    "                    VALUES (\n",
    "                        %s,%s,%s,\n",
    "                        %s,%s,%s,%s,%s,\n",
    "                        %s,%s,%s,%s,\n",
    "                        %s,%s,%s,%s,\n",
    "                        %s,%s,\n",
    "                        %s,%s,%s,%s,%s,\n",
    "                        %s,%s,%s,%s,\n",
    "                        %s,%s,%s,%s,\n",
    "                        %s,%s\n",
    "                    )\n",
    "                \"\"\", (\n",
    "                    str(sample_id), label, note,\n",
    "\n",
    "                    back_sha, back_raw_format, back_raw_w, back_raw_h, psycopg2.Binary(back_raw_bytes),\n",
    "                    back_proc_format, back_proc_w, back_proc_h, psycopg2.Binary(back_proc_bytes),\n",
    "                    back_mask_format, back_mask_w, back_mask_h, psycopg2.Binary(back_mask_bytes) if back_mask_bytes else None,\n",
    "                    back_proc_method, float(back_proc_quad_expand) if back_proc_quad_expand is not None else None,\n",
    "\n",
    "                    front_sha, front_raw_format, front_raw_w, front_raw_h, psycopg2.Binary(front_raw_bytes),\n",
    "                    front_proc_format, front_proc_w, front_proc_h, psycopg2.Binary(front_proc_bytes),\n",
    "                    front_mask_format, front_mask_w, front_mask_h, psycopg2.Binary(front_mask_bytes) if front_mask_bytes else None,\n",
    "                    front_proc_method, float(front_proc_quad_expand) if front_proc_quad_expand is not None else None,\n",
    "                ))\n",
    "        return True, str(sample_id), back_sha, front_sha, \"‚úÖ Gespeichert (Front+Back).\"\n",
    "    except Exception as e:\n",
    "        return False, None, back_sha, front_sha, \"‚ùå DB-Fehler:\\n\" + fmt_pg_error(e) + \"\\n\\n\" + traceback.format_exc()\n",
    "\n",
    "def approve_and_save(state, user_note, label_override):\n",
    "    if state is None:\n",
    "        return \"‚ùå Kein Analyse-State. Bitte erst analysieren.\", db_counts()\n",
    "\n",
    "    predicted = state[\"combined\"][\"status\"][\"final_label\"]\n",
    "    if predicted not in LABELS:\n",
    "        return f\"‚ùå Interner Fehler: predicted label ung√ºltig: {predicted}\", db_counts()\n",
    "\n",
    "    label_used = label_override if label_override in LABELS else predicted\n",
    "    was_corrected = (label_used != predicted)\n",
    "\n",
    "    note_obj = {\n",
    "        \"user_note\": (user_note or \"\").strip(),\n",
    "        \"predicted_combined\": predicted,\n",
    "        \"predicted_back\": state[\"back\"][\"status\"][\"final_label\"],\n",
    "        \"predicted_front\": state[\"front\"][\"status\"][\"final_label\"],\n",
    "        \"label_used\": label_used,\n",
    "        \"was_corrected\": was_corrected,\n",
    "        \"combined\": state[\"combined\"][\"status\"],\n",
    "        \"back\": state[\"back\"][\"status\"],\n",
    "        \"front\": state[\"front\"][\"status\"],\n",
    "        \"grade_combined\": state.get(\"_grade_combined\"),\n",
    "        \"grade_meta_combined\": state.get(\"_grade_meta_combined\"),\n",
    "    }\n",
    "    note = json.dumps(note_obj, ensure_ascii=False)\n",
    "\n",
    "    back_pil = state.get(\"_last_back_pil\")\n",
    "    front_pil = state.get(\"_last_front_pil\")\n",
    "    if back_pil is None or front_pil is None:\n",
    "        return \"‚ùå Interner Fehler: Upload-Images fehlen im State.\", db_counts()\n",
    "\n",
    "    back_fixed = ImageOps.exif_transpose(back_pil).convert(\"RGB\")\n",
    "    front_fixed = ImageOps.exif_transpose(front_pil).convert(\"RGB\")\n",
    "    back_w, back_h = back_fixed.size\n",
    "    front_w, front_h = front_fixed.size\n",
    "\n",
    "    back_raw_bytes = pil_to_jpeg_bytes(back_fixed, 92)\n",
    "    front_raw_bytes = pil_to_jpeg_bytes(front_fixed, 92)\n",
    "\n",
    "    back_proc_np = state.get(\"_proc_back_np\")\n",
    "    front_proc_np = state.get(\"_proc_front_np\")\n",
    "    if back_proc_np is None or front_proc_np is None:\n",
    "        return \"‚ùå Interner Fehler: proc fehlt im State.\", db_counts()\n",
    "\n",
    "    okb, encb = cv2.imencode(\".png\", cv2.cvtColor(back_proc_np, cv2.COLOR_RGB2BGR))\n",
    "    okf, encf = cv2.imencode(\".png\", cv2.cvtColor(front_proc_np, cv2.COLOR_RGB2BGR))\n",
    "    if not okb or not okf:\n",
    "        return \"‚ùå Konnte proc PNG nicht encodieren.\", db_counts()\n",
    "    back_proc_png = encb.tobytes()\n",
    "    front_proc_png = encf.tobytes()\n",
    "\n",
    "    back_mask = state.get(\"_mask_back_np\")\n",
    "    front_mask = state.get(\"_mask_front_np\")\n",
    "    back_mask_png = encode_png_bytes_gray(back_mask) if back_mask is not None else None\n",
    "    front_mask_png = encode_png_bytes_gray(front_mask) if front_mask is not None else None\n",
    "\n",
    "    back_meta = state.get(\"_meta_back\") or {}\n",
    "    front_meta = state.get(\"_meta_front\") or {}\n",
    "\n",
    "    ok, new_id, back_sha, front_sha, msg = insert_sample_fb(\n",
    "        label=label_used,\n",
    "        note=note,\n",
    "\n",
    "        back_raw_bytes=back_raw_bytes, back_raw_format=\"jpeg\", back_raw_w=back_w, back_raw_h=back_h,\n",
    "        back_proc_bytes=back_proc_png, back_proc_format=\"png\", back_proc_w=IMG_W, back_proc_h=IMG_H,\n",
    "        back_mask_bytes=back_mask_png, back_proc_method=back_meta.get(\"method\"), back_proc_quad_expand=back_meta.get(\"quad_expand\"),\n",
    "\n",
    "        front_raw_bytes=front_raw_bytes, front_raw_format=\"jpeg\", front_raw_w=front_w, front_raw_h=front_h,\n",
    "        front_proc_bytes=front_proc_png, front_proc_format=\"png\", front_proc_w=IMG_W, front_proc_h=IMG_H,\n",
    "        front_mask_bytes=front_mask_png, front_proc_method=front_meta.get(\"method\"), front_proc_quad_expand=front_meta.get(\"quad_expand\"),\n",
    "    )\n",
    "\n",
    "    if ok:\n",
    "        try:\n",
    "            rebuild_all_caches()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        extra = \" (korrigiert)\" if was_corrected else \"\"\n",
    "        return f\"‚úÖ Gespeichert: {label_used}{extra}. id={new_id[:8]} back_sha={back_sha[:10]} front_sha={front_sha[:10]}\", db_counts()\n",
    "\n",
    "    return msg, db_counts()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Plot + PDF Report (1 Seite) ‚Äî PLOTS ONLY\n",
    "# =========================\n",
    "def plot_compact_onepage(probs_c, probs_b, probs_f, out_path: str):\n",
    "    fig = plt.figure(figsize=(8.2, 7.2))\n",
    "    x = np.arange(len(LABELS))\n",
    "\n",
    "    ax1 = fig.add_subplot(3, 1, 1)\n",
    "    ax1.bar(x, probs_c)\n",
    "    ax1.set_xticks(x, LABELS)\n",
    "    ax1.set_ylim(0, 1.0)\n",
    "    ax1.set_title(\"Combined probabilities (Front+Back)\")\n",
    "    ax1.set_ylabel(\"Prob\")\n",
    "\n",
    "    ax2 = fig.add_subplot(3, 1, 2)\n",
    "    ax2.bar(x, probs_b)\n",
    "    ax2.set_xticks(x, LABELS)\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    ax2.set_title(\"BACK probabilities\")\n",
    "    ax2.set_ylabel(\"Prob\")\n",
    "\n",
    "    ax3 = fig.add_subplot(3, 1, 3)\n",
    "    ax3.bar(x, probs_f)\n",
    "    ax3.set_xticks(x, LABELS)\n",
    "    ax3.set_ylim(0, 1.0)\n",
    "    ax3.set_title(\"FRONT probabilities\")\n",
    "    ax3.set_ylabel(\"Prob\")\n",
    "\n",
    "    fig.tight_layout(pad=2.0, h_pad=1.2)\n",
    "    fig.savefig(out_path, dpi=220)\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "def build_pdf_report_1page(\n",
    "    out_pdf_path: str,\n",
    "    plot_path: str,\n",
    "    status_combined: dict,\n",
    "    status_back: dict,\n",
    "    status_front: dict,\n",
    "):\n",
    "    c = canvas.Canvas(out_pdf_path, pagesize=A4)\n",
    "    W, H = A4\n",
    "\n",
    "    M = 16 * mm\n",
    "    G = 8 * mm\n",
    "    header_h = 22 * mm\n",
    "\n",
    "    CARD_PAD = 10\n",
    "    TITLE_BAND = 20\n",
    "    TITLE_BASELINE = 14\n",
    "\n",
    "    def draw_header(title: str, subtitle: str):\n",
    "        c.setFillColor(colors.HexColor(\"#0B1220\"))\n",
    "        c.rect(0, H - header_h, W, header_h, stroke=0, fill=1)\n",
    "        c.setFillColor(colors.white)\n",
    "        c.setFont(\"Helvetica-Bold\", 16)\n",
    "        c.drawString(M, H - 14 * mm, title)\n",
    "        c.setFont(\"Helvetica\", 9.5)\n",
    "        c.setFillColor(colors.HexColor(\"#C9D4F2\"))\n",
    "        c.drawString(M, H - 19 * mm, subtitle)\n",
    "\n",
    "    def draw_card(x, y, w, h, title=None):\n",
    "        c.setFillColor(colors.white)\n",
    "        c.setStrokeColor(colors.HexColor(\"#E6EAF2\"))\n",
    "        c.setLineWidth(1)\n",
    "        c.roundRect(x, y, w, h, 10, stroke=1, fill=1)\n",
    "        if title:\n",
    "            c.setFillColor(colors.HexColor(\"#111827\"))\n",
    "            c.setFont(\"Helvetica-Bold\", 10.5)\n",
    "            c.drawString(x + CARD_PAD, y + h - TITLE_BASELINE, title)\n",
    "        reserved_top = TITLE_BAND if title else 0\n",
    "        inner_x = x + CARD_PAD\n",
    "        inner_y = y + CARD_PAD\n",
    "        inner_w = w - 2 * CARD_PAD\n",
    "        inner_h = h - 2 * CARD_PAD - reserved_top\n",
    "        return inner_x, inner_y, inner_w, inner_h\n",
    "\n",
    "    def draw_kv(x, y, key, val, key_w=78, font_size=9.8):\n",
    "        c.setFont(\"Helvetica-Bold\", font_size)\n",
    "        c.setFillColor(colors.HexColor(\"#111827\"))\n",
    "        c.drawString(x, y, key)\n",
    "        c.setFont(\"Helvetica\", font_size)\n",
    "        c.setFillColor(colors.HexColor(\"#374151\"))\n",
    "        c.drawString(x + key_w, y, val)\n",
    "\n",
    "    def draw_grade_badge(x, y, w, h, grade: int, label: str, sublabel: str):\n",
    "        if grade >= 9:\n",
    "            bg = colors.HexColor(\"#0B3D2E\")\n",
    "        elif grade >= 7:\n",
    "            bg = colors.HexColor(\"#123B6D\")\n",
    "        elif grade >= 5:\n",
    "            bg = colors.HexColor(\"#5A3B00\")\n",
    "        elif grade >= 3:\n",
    "            bg = colors.HexColor(\"#6D1A1A\")\n",
    "        else:\n",
    "            bg = colors.HexColor(\"#2B2B2B\")\n",
    "\n",
    "        c.setFillColor(bg)\n",
    "        c.setStrokeColor(colors.HexColor(\"#111827\"))\n",
    "        c.setLineWidth(1)\n",
    "        c.roundRect(x, y, w, h, 18, stroke=1, fill=1)\n",
    "\n",
    "        c.setStrokeColor(colors.HexColor(\"#FFFFFF\"))\n",
    "        c.setLineWidth(0.6)\n",
    "        c.roundRect(x+3, y+3, w-6, h-6, 16, stroke=1, fill=0)\n",
    "\n",
    "        c.setFillColor(colors.white)\n",
    "        c.setFont(\"Helvetica-Bold\", 46)\n",
    "        g = format_grade(grade)\n",
    "        tw = stringWidth(g, \"Helvetica-Bold\", 46)\n",
    "        c.drawString(x + (w - tw)/2, y + h*0.60 - 24, g)\n",
    "\n",
    "        c.setFont(\"Helvetica-Bold\", 11)\n",
    "        tw2 = stringWidth(label, \"Helvetica-Bold\", 11)\n",
    "        c.drawString(x + (w - tw2)/2, y + 16, label)\n",
    "\n",
    "        c.setFont(\"Helvetica\", 8.8)\n",
    "        c.setFillColor(colors.HexColor(\"#E5E7EB\"))\n",
    "        tw3 = stringWidth(sublabel, \"Helvetica\", 8.8)\n",
    "        c.drawString(x + (w - tw3)/2, y + 6, sublabel)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    comb_label = status_combined.get(\"final_label\", \"?\")\n",
    "    comb_grade = float(status_combined.get(\"grade\", 0))\n",
    "\n",
    "    back_label = status_back.get(\"final_label\", \"?\")\n",
    "    back_grade = int(status_back.get(\"grade\", 0))\n",
    "\n",
    "    front_label = status_front.get(\"final_label\", \"?\")\n",
    "    front_grade = int(status_front.get(\"grade\", 0))\n",
    "\n",
    "    draw_header(\"Pokemon TCG Grading Report\", f\"Generated {now}  ‚Ä¢  Final = Combined (Front+Back)\")\n",
    "\n",
    "    content_top = H - header_h - M\n",
    "\n",
    "    badge_w = 62 * mm\n",
    "    badge_h = 42 * mm\n",
    "    badge_x = W - M - badge_w\n",
    "    badge_y = content_top - badge_h\n",
    "\n",
    "    draw_grade_badge(\n",
    "        badge_x, badge_y, badge_w, badge_h,\n",
    "        int(comb_grade),\n",
    "        \"CERTIFIED GRADE\",\n",
    "        f\"Condition: {comb_label}\"\n",
    "    )\n",
    "\n",
    "    sum_x = M\n",
    "    sum_y = badge_y\n",
    "    sum_w = badge_x - M - G\n",
    "    sum_h = badge_h\n",
    "    sx, sy, sw, sh = draw_card(sum_x, sum_y, sum_w, sum_h, title=\"Results (Combined + Sides)\")\n",
    "\n",
    "    draw_kv(sx, sy + sh - 16, \"Combined:\", f\"{comb_label}  ‚Ä¢ Grade {comb_grade}/10\")\n",
    "    draw_kv(sx, sy + sh - 30, \"Back:\",     f\"{back_label}  ‚Ä¢ Grade {back_grade}/10\")\n",
    "    draw_kv(sx, sy + sh - 44, \"Front:\",    f\"{front_label} ‚Ä¢ Grade {front_grade}/10\")\n",
    "\n",
    "    # --- PLOTS (full width) ---\n",
    "    plot_h = 150 * mm\n",
    "    plot_y = sum_y - G - plot_h\n",
    "    px, py, pw, ph = draw_card(M, plot_y, W - 2*M, plot_h, title=\"Plots\")\n",
    "    try:\n",
    "        c.drawImage(ImageReader(plot_path), px, py, width=pw, height=ph, preserveAspectRatio=True, anchor='c')\n",
    "    except:\n",
    "        c.setFont(\"Helvetica\", 10)\n",
    "        c.setFillColor(colors.HexColor(\"#B91C1C\"))\n",
    "        c.drawString(px, py + ph/2, \"Plot could not be loaded.\")\n",
    "\n",
    "    c.setFont(\"Helvetica\", 7.5)\n",
    "    c.setFillColor(colors.HexColor(\"#6B7280\"))\n",
    "    c.drawString(M, 10*mm, \"AI-assisted estimate. Inspect under proper lighting; official grading may differ.\")\n",
    "\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Gradio UI (BACK + FRONT Pflicht) ‚Äî 1-Page PDF (Plots only)\n",
    "# =========================\n",
    "with gr.Blocks(title=\"Pokemon Condition (Combined Front+Back) + Approve + 1-page PDF (Plots)\") as app2:\n",
    "    gr.Markdown(\n",
    "        \"# üß† Notebook 2: Analyse (Front+Back Pflicht)\\n\"\n",
    "    )\n",
    "\n",
    "    state = gr.State(None)\n",
    "\n",
    "    with gr.Row():\n",
    "        back_in = gr.Image(label=\"Upload: R√ºckseite (Pflicht)\", type=\"pil\")\n",
    "        front_in = gr.Image(label=\"Upload: Vorderseite (Pflicht)\", type=\"pil\")\n",
    "\n",
    "    with gr.Row():\n",
    "        back_proc_prev = gr.Image(label=\"BACK Proc Preview (Analyse Input)\", type=\"pil\")\n",
    "        front_proc_prev = gr.Image(label=\"FRONT Proc Preview (Analyse Input)\", type=\"pil\")\n",
    "\n",
    "    with gr.Row():\n",
    "        btn_analyze = gr.Button(\"Analysieren (x10) + PDF\", variant=\"primary\")\n",
    "        btn_approve = gr.Button(\"‚úÖ Zustimmen & Speichern (Label=Combined)\", variant=\"secondary\")\n",
    "        btn_recache = gr.Button(\"üîÑ Cache neu laden\", variant=\"secondary\")\n",
    "\n",
    "    final_txt = gr.Textbox(label=\"FINAL Ergebnis (Combined)\", interactive=False)\n",
    "    comb_txt  = gr.Textbox(label=\"Combined Details\", interactive=False)\n",
    "    back_txt  = gr.Textbox(label=\"BACK Ergebnis (Details)\", interactive=False)\n",
    "    front_txt = gr.Textbox(label=\"FRONT Ergebnis (Details)\", interactive=False)\n",
    "\n",
    "    pregrade_txt = gr.Textbox(label=\"Pregrading (1-10) [Combined]\", interactive=False)\n",
    "    pdf_out = gr.File(label=\"üìÑ PDF Report (1 Seite)\")\n",
    "\n",
    "    label_override = gr.Dropdown(\n",
    "        choices=[\"AUTO (Model)\"] + LABELS,\n",
    "        value=\"AUTO (Model)\",\n",
    "        label=\"Falls falsch: richtiges Label ausw√§hlen (optional)\"\n",
    "    )\n",
    "    note = gr.Textbox(label=\"Notiz (optional)\", placeholder=\"z.B. 'Back NM, Front minimal Whitening'\")\n",
    "\n",
    "    status_json = gr.JSON(label=\"Details (Combined + Back + Front)\")\n",
    "    with gr.Row():\n",
    "        gallery_back = gr.Gallery(label=f\"Top-{TOPK} Referenzen (BACK)\", columns=4, height=\"auto\")\n",
    "        gallery_front = gr.Gallery(label=f\"Top-{TOPK} Referenzen (FRONT)\", columns=4, height=\"auto\")\n",
    "\n",
    "    save_msg = gr.Textbox(label=\"Speicher-Status\", interactive=False)\n",
    "    counts = gr.JSON(label=\"DB Counts\")\n",
    "\n",
    "    def on_analyze(back_pil, front_pil):\n",
    "        try:\n",
    "            if back_pil is None or front_pil is None:\n",
    "                return (\n",
    "                    None, None, None, [], [], None,\n",
    "                    \"‚ùå Bitte R√ºckseite UND Vorderseite hochladen.\",\n",
    "                    \"\", \"\", \"\", \"\", \"\",\n",
    "                    None, \"AUTO (Model)\", db_counts()\n",
    "                )\n",
    "\n",
    "            back_proc_np, back_mask, _back_dbg, back_meta = preprocess_pil_to_proc_rgb(back_pil, side=\"back\")\n",
    "            front_proc_np, front_mask, _front_dbg, front_meta = preprocess_pil_to_proc_rgb(front_pil, side=\"front\")\n",
    "\n",
    "            back_proc_prev_pil = Image.fromarray(back_proc_np)\n",
    "            front_proc_prev_pil = Image.fromarray(front_proc_np)\n",
    "\n",
    "            if REQUIRE_EXTRACTION and ((not back_meta.get(\"extracted\")) or (not front_meta.get(\"extracted\"))):\n",
    "                msg = (\n",
    "                    \"‚ùå Karte konnte nicht sauber erkannt/gewrappt werden (Quad/Warp).\\n\"\n",
    "                    \"Tipps: Karte n√§her, gerade, ohne starken Schatten/Glanz; blauer Rand vollst√§ndig im Bild.\"\n",
    "                )\n",
    "                return (\n",
    "                    None,\n",
    "                    back_proc_prev_pil, front_proc_prev_pil,\n",
    "                    [], [], None,\n",
    "                    msg,\n",
    "                    \"\", \"\", \"\", \"\", \"\",\n",
    "                    None, \"AUTO (Model)\", db_counts()\n",
    "                )\n",
    "\n",
    "            status_b, gal_b, st_b, txt_b, probs_b, idxs_b, sims_b, grade_b, grade_meta_b = analyze_ensemble(\n",
    "                \"back\", back_proc_np, n_runs=ENSEMBLE_RUNS\n",
    "            )\n",
    "            status_f, gal_f, st_f, txt_f, probs_f, idxs_f, sims_f, grade_f, grade_meta_f = analyze_ensemble(\n",
    "                \"front\", front_proc_np, n_runs=ENSEMBLE_RUNS\n",
    "            )\n",
    "\n",
    "            status_c, probs_c, st_c, grade_c, grade_meta_c = compute_combined(\n",
    "                status_b, probs_b, sims_b, st_b, grade_b, grade_meta_b,\n",
    "                status_f, probs_f, sims_f, st_f, grade_f, grade_meta_f\n",
    "            )\n",
    "\n",
    "            run_id = uuid.uuid4().hex[:10]\n",
    "            plot_path = os.path.join(REPORT_DIR, f\"compact_plot_{run_id}.png\")\n",
    "            pdf_path  = os.path.join(REPORT_DIR, f\"grading_report_{run_id}.pdf\")\n",
    "\n",
    "            plot_compact_onepage(probs_c, probs_b, probs_f, plot_path)\n",
    "            build_pdf_report_1page(\n",
    "                out_pdf_path=pdf_path,\n",
    "                plot_path=plot_path,\n",
    "                status_combined=status_c,\n",
    "                status_back=status_b,\n",
    "                status_front=status_f,\n",
    "            )\n",
    "\n",
    "            pre_txt = pregrading_text(status_c[\"final_label\"], int(grade_c))\n",
    "\n",
    "            votes_b = status_b.get(\"ensemble\", {}).get(\"label_counts\", {})\n",
    "            votes_f = status_f.get(\"ensemble\", {}).get(\"label_counts\", {})\n",
    "\n",
    "            votes_b_str = \" | \".join([f\"{k}:{v}\" for k, v in votes_b.items() if v > 0]) or str(votes_b)\n",
    "            votes_f_str = \" | \".join([f\"{k}:{v}\" for k, v in votes_f.items() if v > 0]) or str(votes_f)\n",
    "\n",
    "            final_line = f\"FINAL (Combined): {status_c['final_label']} | Grade {int(grade_c)}/10\"\n",
    "            comb_line = f\"COMBINED: {status_c['final_label']} | Grade {int(grade_c)}/10 | {status_c.get('final_source')}\"\n",
    "            back_line  = f\"{txt_b}\\nVotes: {votes_b_str}\"\n",
    "            front_line = f\"{txt_f}\\nVotes: {votes_f_str}\"\n",
    "\n",
    "            combined_state = {\n",
    "                \"combined\": st_c,\n",
    "                \"back\": st_b,\n",
    "                \"front\": st_f,\n",
    "\n",
    "                \"_last_back_pil\": back_pil,\n",
    "                \"_last_front_pil\": front_pil,\n",
    "                \"_proc_back_np\": back_proc_np,\n",
    "                \"_proc_front_np\": front_proc_np,\n",
    "                \"_mask_back_np\": back_mask,\n",
    "                \"_mask_front_np\": front_mask,\n",
    "                \"_meta_back\": back_meta,\n",
    "                \"_meta_front\": front_meta,\n",
    "\n",
    "                \"_pdf_path\": pdf_path,\n",
    "                \"_grade_combined\": int(grade_c),\n",
    "                \"_grade_meta_combined\": grade_meta_c,\n",
    "            }\n",
    "\n",
    "            status_all = {\"combined\": status_c, \"back\": status_b, \"front\": status_f}\n",
    "\n",
    "            return (\n",
    "                status_all,\n",
    "                back_proc_prev_pil, front_proc_prev_pil,\n",
    "                gal_b, gal_f,\n",
    "                combined_state,\n",
    "                \"\",\n",
    "                final_line, comb_line, back_line, front_line,\n",
    "                pre_txt,\n",
    "                pdf_path,\n",
    "                \"AUTO (Model)\",\n",
    "                db_counts()\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            err = f\"‚ùå Fehler in on_analyze:\\n{type(e).__name__}: {e}\\n\\n{traceback.format_exc()}\"\n",
    "            return (\n",
    "                None, None, None, [], [], None,\n",
    "                err,\n",
    "                \"\", \"\", \"\", \"\", \"\",\n",
    "                None, \"AUTO (Model)\", db_counts()\n",
    "            )\n",
    "\n",
    "    def on_approve(st, user_note, override_choice):\n",
    "        override = override_choice if override_choice in LABELS else None\n",
    "        return approve_and_save(st, user_note, override)\n",
    "\n",
    "    def on_recache():\n",
    "        rebuild_all_caches()\n",
    "        return \"‚úÖ Cache neu geladen (Back/Front/Combined).\", db_counts()\n",
    "\n",
    "    btn_analyze.click(\n",
    "        fn=on_analyze,\n",
    "        inputs=[back_in, front_in],\n",
    "        outputs=[\n",
    "            status_json, back_proc_prev, front_proc_prev, gallery_back, gallery_front, state,\n",
    "            save_msg, final_txt, comb_txt, back_txt, front_txt, pregrade_txt, pdf_out, label_override, counts\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    btn_approve.click(\n",
    "        fn=on_approve,\n",
    "        inputs=[state, note, label_override],\n",
    "        outputs=[save_msg, counts]\n",
    "    )\n",
    "\n",
    "    btn_recache.click(\n",
    "        fn=on_recache,\n",
    "        inputs=[],\n",
    "        outputs=[save_msg, counts]\n",
    "    )\n",
    "\n",
    "    counts.value = db_counts()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Server Start (freier Port)\n",
    "# =========================\n",
    "def guess_local_ip():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    try:\n",
    "        s.connect((\"10.255.255.255\", 1))\n",
    "        ip = s.getsockname()[0]\n",
    "    except Exception:\n",
    "        ip = \"127.0.0.1\"\n",
    "    finally:\n",
    "        s.close()\n",
    "    return ip\n",
    "\n",
    "def get_free_port():\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((\"\", 0))\n",
    "    port = s.getsockname()[1]\n",
    "    s.close()\n",
    "    return port\n",
    "\n",
    "local_ip = guess_local_ip()\n",
    "port = get_free_port()\n",
    "\n",
    "print(f\"üëâ √ñffne am Handy (gleiches WLAN): http://{local_ip}:{port}\")\n",
    "app2.launch(server_name=\"0.0.0.0\", server_port=port, share=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv310 (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
